/* Generated by ./src/xlat/gen.sh from ./src/xlat/v4l2_pix_fmts.in; do not edit. */

#include "gcc_compat.h"
#include "static_assert.h"

#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_Y10)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_Y10"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_Y10)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_Y12)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_Y12"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_Y12)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_Y4)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_Y4"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_Y4)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_Y14)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_Y14"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_Y14)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_Y6)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_Y6"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_Y6)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_Y16)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_Y16"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_Y16)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_Z16)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_Z16"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_Z16)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_UV8)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_UV8"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_UV8)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_Y8I)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_Y8I"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_Y8I)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_MR97310A)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_MR97310A"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_MR97310A)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SN9C10X)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SN9C10X"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SN9C10X)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SGRBG10)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SGRBG10"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SGRBG10)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SGBRG10)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SGBRG10"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SGBRG10)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SGRBG10DPCM8)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SGRBG10DPCM8"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SGRBG10DPCM8)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SBGGR10)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SBGGR10"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SBGGR10)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SRGGB10)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SRGGB10"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SRGGB10)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_M420)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_M420"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_M420)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SN9C20X_I420)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SN9C20X_I420"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SN9C20X_I420)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_JL2005BCD)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_JL2005BCD"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_JL2005BCD)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_TM6000)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_TM6000"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_TM6000)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_STV0680)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_STV0680"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_STV0680)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_VP8)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_VP8"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_VP8)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_VP9)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_VP9"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_VP9)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SE401)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SE401"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SE401)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SPCA501)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SPCA501"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SPCA501)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_OV511)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_OV511"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_OV511)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_MM21)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_MM21"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_MM21)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_NV21M)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_NV21M"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_NV21M)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_YVU420M)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_YVU420M"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_YVU420M)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_MT21C)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_MT21C"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_MT21C)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_NV21)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_NV21"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_NV21)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SPCA561)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SPCA561"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SPCA561)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_NV61M)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_NV61M"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_NV61M)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_YVU422M)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_YVU422M"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_YVU422M)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_NV61)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_NV61"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_NV61)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SBGGR8)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SBGGR8"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SBGGR8)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_RGB332)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_RGB332"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_RGB332)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_H264_NO_SC)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_H264_NO_SC"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_H264_NO_SC)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_PWC1)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_PWC1"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_PWC1)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_MPEG1)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_MPEG1"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_MPEG1)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SGRBG12)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SGRBG12"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SGRBG12)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_BGRA444)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_BGRA444"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_BGRA444)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_NV12M_8L128)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_NV12M_8L128"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_NV12M_8L128)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_RGBA444)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_RGBA444"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_RGBA444)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_ABGR444)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_ABGR444"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_ABGR444)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SGBRG12)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SGBRG12"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SGBRG12)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_XBGR444)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_XBGR444"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_XBGR444)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SBGGR12)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SBGGR12"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SBGGR12)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SRGGB12)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SRGGB12"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SRGGB12)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_NV12_16L16)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_NV12_16L16"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_NV12_16L16)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_NV12M)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_NV12M"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_NV12M)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_NV12MT)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_NV12MT"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_NV12MT)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_NV12MT_16X16)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_NV12MT_16X16"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_NV12MT_16X16)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_YUV420M)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_YUV420M"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_YUV420M)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_ARGB444)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_ARGB444"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_ARGB444)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_XRGB444)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_XRGB444"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_XRGB444)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_NV12_32L32)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_NV12_32L32"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_NV12_32L32)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_NV12_4L4)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_NV12_4L4"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_NV12_4L4)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_YUV420)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_YUV420"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_YUV420)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_NV12)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_NV12"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_NV12)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_YVU420)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_YVU420"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_YVU420)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_BGRX444)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_BGRX444"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_BGRX444)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_RGBX444)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_RGBX444"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_RGBX444)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_YVU444M)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_YVU444M"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_YVU444M)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_NV42)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_NV42"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_NV42)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_PWC2)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_PWC2"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_PWC2)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_MPEG2)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_MPEG2"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_MPEG2)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SBGGR16)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SBGGR16"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SBGGR16)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_H263)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_H263"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_H263)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_RGB24)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_RGB24"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_RGB24)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_BGR24)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_BGR24"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_BGR24)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_HSV24)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_HSV24"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_HSV24)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_YUV24)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_YUV24"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_YUV24)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SGBRG14)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SGBRG14"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SGBRG14)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SBGGR14)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SBGGR14"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SBGGR14)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SRGGB14)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SRGGB14"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SRGGB14)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SGRBG14)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SGRBG14"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SGRBG14)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_ARGB32)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_ARGB32"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_ARGB32)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_BGRA32)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_BGRA32"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_BGRA32)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_RGBA32)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_RGBA32"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_RGBA32)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_RGBX32)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_RGBX32"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_RGBX32)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_HI240)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_HI240"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_HI240)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_YUV444M)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_YUV444M"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_YUV444M)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_ABGR32)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_ABGR32"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_ABGR32)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_XBGR32)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_XBGR32"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_XBGR32)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_NV24)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_NV24"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_NV24)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_XRGB32)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_XRGB32"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_XRGB32)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_BGRX32)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_BGRX32"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_BGRX32)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_RGB444)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_RGB444"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_RGB444)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_YUV444)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_YUV444"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_YUV444)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_H264)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_H264"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_H264)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_H264_MVC)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_H264_MVC"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_H264_MVC)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_H264_SLICE)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_H264_SLICE"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_H264_SLICE)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_RGB32)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_RGB32"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_RGB32)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_CNF4)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_CNF4"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_CNF4)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_MPEG4)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_MPEG4"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_MPEG4)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_BGR32)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_BGR32"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_BGR32)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_HSV32)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_HSV32"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_HSV32)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_YUV32)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_YUV32"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_YUV32)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SPCA505)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SPCA505"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SPCA505)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_BGRA555)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_BGRA555"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_BGRA555)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_RGBA555)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_RGBA555"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_RGBA555)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_ABGR555)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_ABGR555"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_ABGR555)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_XBGR555)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_XBGR555"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_XBGR555)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_ARGB555)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_ARGB555"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_ARGB555)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_XRGB555)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_XRGB555"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_XRGB555)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_BGRX555)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_BGRX555"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_BGRX555)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_RGBX555)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_RGBX555"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_RGBX555)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_ET61X251)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_ET61X251"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_ET61X251)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SGBRG16)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SGBRG16"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SGBRG16)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SRGGB16)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SRGGB16"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SRGGB16)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_NV16M)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_NV16M"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_NV16M)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_YUV422M)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_YUV422M"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_YUV422M)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SGRBG16)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SGRBG16"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SGRBG16)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_NV16)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_NV16"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_NV16)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_PAC207)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_PAC207"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_PAC207)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SPCA508)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SPCA508"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SPCA508)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_OV518)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_OV518"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_OV518)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SBGGR10ALAW8)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SBGGR10ALAW8"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SBGGR10ALAW8)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SBGGR10DPCM8)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SBGGR10DPCM8"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SBGGR10DPCM8)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SGBRG10ALAW8)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SGBRG10ALAW8"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SGBRG10ALAW8)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SGBRG10DPCM8)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SGBRG10DPCM8"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SGBRG10DPCM8)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SRGGB10ALAW8)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SRGGB10ALAW8"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SRGGB10ALAW8)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SRGGB10DPCM8)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SRGGB10DPCM8"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SRGGB10DPCM8)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SGRBG10ALAW8)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SGRBG10ALAW8"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SGRBG10ALAW8)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_PAL8)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_PAL8"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_PAL8)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_YVU410)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_YVU410"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_YVU410)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_YUV410)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_YUV410"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_YUV410)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SBGGR10P)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SBGGR10P"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SBGGR10P)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SGBRG10P)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SGBRG10P"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SGBRG10P)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SRGGB10P)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SRGGB10P"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SRGGB10P)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SGRBG10P)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SGRBG10P"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SGRBG10P)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_CPIA1)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_CPIA1"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_CPIA1)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_WNVA)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_WNVA"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_WNVA)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_VUYA32)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_VUYA32"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_VUYA32)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_Y10BPACK)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_Y10BPACK"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_Y10BPACK)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SRGGB8)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SRGGB8"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SRGGB8)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_QC10C)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_QC10C"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_QC10C)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SQ905C)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SQ905C"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SQ905C)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_QC08C)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_QC08C"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_QC08C)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SBGGR12P)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SBGGR12P"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SBGGR12P)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SGBRG12P)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SGBRG12P"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SGBRG12P)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SRGGB12P)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SRGGB12P"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SRGGB12P)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SGRBG12P)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SGRBG12P"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SGRBG12P)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_HEVC)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_HEVC"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_HEVC)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_XVID)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_XVID"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_XVID)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SBGGR14P)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SBGGR14P"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SBGGR14P)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SGBRG14P)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SGBRG14P"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SGBRG14P)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SRGGB14P)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SRGGB14P"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SRGGB14P)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SGRBG14P)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SGRBG14P"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SGRBG14P)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_VP8_FRAME)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_VP8_FRAME"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_VP8_FRAME)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_VP9_FRAME)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_VP9_FRAME"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_VP9_FRAME)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_VC1_ANNEX_G)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_VC1_ANNEX_G"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_VC1_ANNEX_G)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_IPU3_SGRBG10)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_IPU3_SGRBG10"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_IPU3_SGRBG10)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SGRBG8)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SGRBG8"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SGRBG8)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_JPEG)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_JPEG"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_JPEG)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_MPEG)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_MPEG"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_MPEG)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_MJPEG)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_MJPEG"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_MJPEG)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_PJPG)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_PJPG"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_PJPG)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SGBRG8)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SGBRG8"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SGBRG8)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_BGR666)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_BGR666"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_BGR666)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_FWHT_STATELESS)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_FWHT_STATELESS"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_FWHT_STATELESS)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_Y12I)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_Y12I"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_Y12I)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_S5C_UYVY_JPG)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_S5C_UYVY_JPG"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_S5C_UYVY_JPG)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_KONICA420)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_KONICA420"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_KONICA420)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_INZI)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_INZI"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_INZI)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_VC1_ANNEX_L)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_VC1_ANNEX_L"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_VC1_ANNEX_L)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_JPGL)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_JPGL"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_JPGL)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_RGB555)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_RGB555"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_RGB555)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_YUV555)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_YUV555"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_YUV555)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_Y10P)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_Y10P"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_Y10P)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_YUV411P)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_YUV411P"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_YUV411P)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_Y41P)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_Y41P"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_Y41P)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_YUV422P)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_YUV422P"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_YUV422P)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_RGB565)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_RGB565"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_RGB565)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_YUV565)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_YUV565"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_YUV565)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_RGB555X)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_RGB555X"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_RGB555X)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_RGB565X)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_RGB565X"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_RGB565X)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_MPEG2_SLICE)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_MPEG2_SLICE"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_MPEG2_SLICE)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_FWHT)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_FWHT"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_FWHT)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_YVYU)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_YVYU"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_YVYU)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_CIT_YYVYUY)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_CIT_YYVYUY"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_CIT_YYVYUY)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_AYUV32)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_AYUV32"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_AYUV32)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_XYUV32)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_XYUV32"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_XYUV32)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_YYUV)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_YYUV"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_YYUV)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_YUYV)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_YUYV"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_YUYV)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_SN9C2028)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_SN9C2028"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_SN9C2028)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_VUYX32)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_VUYX32"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_VUYX32)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_GREY)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_GREY"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_GREY)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_VYUY)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_VYUY"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_VYUY)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_UYVY)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_UYVY"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_UYVY)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_IPU3_SBGGR10)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_IPU3_SBGGR10"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_IPU3_SBGGR10)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_DV)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_DV"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_DV)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_IPU3_SGBRG10)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_IPU3_SGBRG10"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_IPU3_SGBRG10)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_IPU3_SRGGB10)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_IPU3_SRGGB10"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_IPU3_SRGGB10)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_IPU3_Y10)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_IPU3_Y10"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_IPU3_Y10)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_Y16_BE)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_Y16_BE"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_Y16_BE)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_NV12M_10BE_8L128)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_NV12M_10BE_8L128"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_NV12M_10BE_8L128)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_ARGB555X)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_ARGB555X"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_ARGB555X)
#if defined XLAT_PREV_VAL
static_assert((unsigned long long) (V4L2_PIX_FMT_XRGB555X)
      > (unsigned long long) (XLAT_PREV_VAL),
      "Incorrect order in #sorted xlat: V4L2_PIX_FMT_XRGB555X"
      " is not larger than the previous value");
#endif
#undef XLAT_PREV_VAL
#define XLAT_PREV_VAL (V4L2_PIX_FMT_XRGB555X)
#undef XLAT_PREV_VAL

#ifndef XLAT_MACROS_ONLY

# ifdef IN_MPERS

extern const struct xlat v4l2_pix_fmts[];

# else

DIAG_PUSH_IGNORE_TAUTOLOGICAL_CONSTANT_COMPARE
static const struct xlat_data v4l2_pix_fmts_xdata[] = {
 XLAT(V4L2_PIX_FMT_Y10),
 #define XLAT_VAL_0 ((unsigned) (V4L2_PIX_FMT_Y10))
 #define XLAT_STR_0 STRINGIFY(V4L2_PIX_FMT_Y10)
 XLAT(V4L2_PIX_FMT_Y12),
 #define XLAT_VAL_1 ((unsigned) (V4L2_PIX_FMT_Y12))
 #define XLAT_STR_1 STRINGIFY(V4L2_PIX_FMT_Y12)
 XLAT(V4L2_PIX_FMT_Y4),
 #define XLAT_VAL_2 ((unsigned) (V4L2_PIX_FMT_Y4))
 #define XLAT_STR_2 STRINGIFY(V4L2_PIX_FMT_Y4)
 XLAT(V4L2_PIX_FMT_Y14),
 #define XLAT_VAL_3 ((unsigned) (V4L2_PIX_FMT_Y14))
 #define XLAT_STR_3 STRINGIFY(V4L2_PIX_FMT_Y14)
 XLAT(V4L2_PIX_FMT_Y6),
 #define XLAT_VAL_4 ((unsigned) (V4L2_PIX_FMT_Y6))
 #define XLAT_STR_4 STRINGIFY(V4L2_PIX_FMT_Y6)
 XLAT(V4L2_PIX_FMT_Y16),
 #define XLAT_VAL_5 ((unsigned) (V4L2_PIX_FMT_Y16))
 #define XLAT_STR_5 STRINGIFY(V4L2_PIX_FMT_Y16)
 XLAT(V4L2_PIX_FMT_Z16),
 #define XLAT_VAL_6 ((unsigned) (V4L2_PIX_FMT_Z16))
 #define XLAT_STR_6 STRINGIFY(V4L2_PIX_FMT_Z16)
 XLAT(V4L2_PIX_FMT_UV8),
 #define XLAT_VAL_7 ((unsigned) (V4L2_PIX_FMT_UV8))
 #define XLAT_STR_7 STRINGIFY(V4L2_PIX_FMT_UV8)
 XLAT(V4L2_PIX_FMT_Y8I),
 #define XLAT_VAL_8 ((unsigned) (V4L2_PIX_FMT_Y8I))
 #define XLAT_STR_8 STRINGIFY(V4L2_PIX_FMT_Y8I)
 XLAT(V4L2_PIX_FMT_MR97310A),
 #define XLAT_VAL_9 ((unsigned) (V4L2_PIX_FMT_MR97310A))
 #define XLAT_STR_9 STRINGIFY(V4L2_PIX_FMT_MR97310A)
 XLAT(V4L2_PIX_FMT_SN9C10X),
 #define XLAT_VAL_10 ((unsigned) (V4L2_PIX_FMT_SN9C10X))
 #define XLAT_STR_10 STRINGIFY(V4L2_PIX_FMT_SN9C10X)
 XLAT(V4L2_PIX_FMT_SGRBG10),
 #define XLAT_VAL_11 ((unsigned) (V4L2_PIX_FMT_SGRBG10))
 #define XLAT_STR_11 STRINGIFY(V4L2_PIX_FMT_SGRBG10)
 XLAT(V4L2_PIX_FMT_SGBRG10),
 #define XLAT_VAL_12 ((unsigned) (V4L2_PIX_FMT_SGBRG10))
 #define XLAT_STR_12 STRINGIFY(V4L2_PIX_FMT_SGBRG10)
 XLAT(V4L2_PIX_FMT_SGRBG10DPCM8),
 #define XLAT_VAL_13 ((unsigned) (V4L2_PIX_FMT_SGRBG10DPCM8))
 #define XLAT_STR_13 STRINGIFY(V4L2_PIX_FMT_SGRBG10DPCM8)
 XLAT(V4L2_PIX_FMT_SBGGR10),
 #define XLAT_VAL_14 ((unsigned) (V4L2_PIX_FMT_SBGGR10))
 #define XLAT_STR_14 STRINGIFY(V4L2_PIX_FMT_SBGGR10)
 XLAT(V4L2_PIX_FMT_SRGGB10),
 #define XLAT_VAL_15 ((unsigned) (V4L2_PIX_FMT_SRGGB10))
 #define XLAT_STR_15 STRINGIFY(V4L2_PIX_FMT_SRGGB10)
 XLAT(V4L2_PIX_FMT_M420),
 #define XLAT_VAL_16 ((unsigned) (V4L2_PIX_FMT_M420))
 #define XLAT_STR_16 STRINGIFY(V4L2_PIX_FMT_M420)
 XLAT(V4L2_PIX_FMT_SN9C20X_I420),
 #define XLAT_VAL_17 ((unsigned) (V4L2_PIX_FMT_SN9C20X_I420))
 #define XLAT_STR_17 STRINGIFY(V4L2_PIX_FMT_SN9C20X_I420)
 XLAT(V4L2_PIX_FMT_JL2005BCD),
 #define XLAT_VAL_18 ((unsigned) (V4L2_PIX_FMT_JL2005BCD))
 #define XLAT_STR_18 STRINGIFY(V4L2_PIX_FMT_JL2005BCD)
 XLAT(V4L2_PIX_FMT_TM6000),
 #define XLAT_VAL_19 ((unsigned) (V4L2_PIX_FMT_TM6000))
 #define XLAT_STR_19 STRINGIFY(V4L2_PIX_FMT_TM6000)
 XLAT(V4L2_PIX_FMT_STV0680),
 #define XLAT_VAL_20 ((unsigned) (V4L2_PIX_FMT_STV0680))
 #define XLAT_STR_20 STRINGIFY(V4L2_PIX_FMT_STV0680)
 XLAT(V4L2_PIX_FMT_VP8),
 #define XLAT_VAL_21 ((unsigned) (V4L2_PIX_FMT_VP8))
 #define XLAT_STR_21 STRINGIFY(V4L2_PIX_FMT_VP8)
 XLAT(V4L2_PIX_FMT_VP9),
 #define XLAT_VAL_22 ((unsigned) (V4L2_PIX_FMT_VP9))
 #define XLAT_STR_22 STRINGIFY(V4L2_PIX_FMT_VP9)
 XLAT(V4L2_PIX_FMT_SE401),
 #define XLAT_VAL_23 ((unsigned) (V4L2_PIX_FMT_SE401))
 #define XLAT_STR_23 STRINGIFY(V4L2_PIX_FMT_SE401)
 XLAT(V4L2_PIX_FMT_SPCA501),
 #define XLAT_VAL_24 ((unsigned) (V4L2_PIX_FMT_SPCA501))
 #define XLAT_STR_24 STRINGIFY(V4L2_PIX_FMT_SPCA501)
 XLAT(V4L2_PIX_FMT_OV511),
 #define XLAT_VAL_25 ((unsigned) (V4L2_PIX_FMT_OV511))
 #define XLAT_STR_25 STRINGIFY(V4L2_PIX_FMT_OV511)
 XLAT(V4L2_PIX_FMT_MM21),
 #define XLAT_VAL_26 ((unsigned) (V4L2_PIX_FMT_MM21))
 #define XLAT_STR_26 STRINGIFY(V4L2_PIX_FMT_MM21)
 XLAT(V4L2_PIX_FMT_NV21M),
 #define XLAT_VAL_27 ((unsigned) (V4L2_PIX_FMT_NV21M))
 #define XLAT_STR_27 STRINGIFY(V4L2_PIX_FMT_NV21M)
 XLAT(V4L2_PIX_FMT_YVU420M),
 #define XLAT_VAL_28 ((unsigned) (V4L2_PIX_FMT_YVU420M))
 #define XLAT_STR_28 STRINGIFY(V4L2_PIX_FMT_YVU420M)
 XLAT(V4L2_PIX_FMT_MT21C),
 #define XLAT_VAL_29 ((unsigned) (V4L2_PIX_FMT_MT21C))
 #define XLAT_STR_29 STRINGIFY(V4L2_PIX_FMT_MT21C)
 XLAT(V4L2_PIX_FMT_NV21),
 #define XLAT_VAL_30 ((unsigned) (V4L2_PIX_FMT_NV21))
 #define XLAT_STR_30 STRINGIFY(V4L2_PIX_FMT_NV21)
 XLAT(V4L2_PIX_FMT_SPCA561),
 #define XLAT_VAL_31 ((unsigned) (V4L2_PIX_FMT_SPCA561))
 #define XLAT_STR_31 STRINGIFY(V4L2_PIX_FMT_SPCA561)
 XLAT(V4L2_PIX_FMT_NV61M),
 #define XLAT_VAL_32 ((unsigned) (V4L2_PIX_FMT_NV61M))
 #define XLAT_STR_32 STRINGIFY(V4L2_PIX_FMT_NV61M)
 XLAT(V4L2_PIX_FMT_YVU422M),
 #define XLAT_VAL_33 ((unsigned) (V4L2_PIX_FMT_YVU422M))
 #define XLAT_STR_33 STRINGIFY(V4L2_PIX_FMT_YVU422M)
 XLAT(V4L2_PIX_FMT_NV61),
 #define XLAT_VAL_34 ((unsigned) (V4L2_PIX_FMT_NV61))
 #define XLAT_STR_34 STRINGIFY(V4L2_PIX_FMT_NV61)
 XLAT(V4L2_PIX_FMT_SBGGR8),
 #define XLAT_VAL_35 ((unsigned) (V4L2_PIX_FMT_SBGGR8))
 #define XLAT_STR_35 STRINGIFY(V4L2_PIX_FMT_SBGGR8)
 XLAT(V4L2_PIX_FMT_RGB332),
 #define XLAT_VAL_36 ((unsigned) (V4L2_PIX_FMT_RGB332))
 #define XLAT_STR_36 STRINGIFY(V4L2_PIX_FMT_RGB332)
 XLAT(V4L2_PIX_FMT_H264_NO_SC),
 #define XLAT_VAL_37 ((unsigned) (V4L2_PIX_FMT_H264_NO_SC))
 #define XLAT_STR_37 STRINGIFY(V4L2_PIX_FMT_H264_NO_SC)
 XLAT(V4L2_PIX_FMT_PWC1),
 #define XLAT_VAL_38 ((unsigned) (V4L2_PIX_FMT_PWC1))
 #define XLAT_STR_38 STRINGIFY(V4L2_PIX_FMT_PWC1)
 XLAT(V4L2_PIX_FMT_MPEG1),
 #define XLAT_VAL_39 ((unsigned) (V4L2_PIX_FMT_MPEG1))
 #define XLAT_STR_39 STRINGIFY(V4L2_PIX_FMT_MPEG1)
 XLAT(V4L2_PIX_FMT_SGRBG12),
 #define XLAT_VAL_40 ((unsigned) (V4L2_PIX_FMT_SGRBG12))
 #define XLAT_STR_40 STRINGIFY(V4L2_PIX_FMT_SGRBG12)
 XLAT(V4L2_PIX_FMT_BGRA444),
 #define XLAT_VAL_41 ((unsigned) (V4L2_PIX_FMT_BGRA444))
 #define XLAT_STR_41 STRINGIFY(V4L2_PIX_FMT_BGRA444)
 XLAT(V4L2_PIX_FMT_NV12M_8L128),
 #define XLAT_VAL_42 ((unsigned) (V4L2_PIX_FMT_NV12M_8L128))
 #define XLAT_STR_42 STRINGIFY(V4L2_PIX_FMT_NV12M_8L128)
 XLAT(V4L2_PIX_FMT_RGBA444),
 #define XLAT_VAL_43 ((unsigned) (V4L2_PIX_FMT_RGBA444))
 #define XLAT_STR_43 STRINGIFY(V4L2_PIX_FMT_RGBA444)
 XLAT(V4L2_PIX_FMT_ABGR444),
 #define XLAT_VAL_44 ((unsigned) (V4L2_PIX_FMT_ABGR444))
 #define XLAT_STR_44 STRINGIFY(V4L2_PIX_FMT_ABGR444)
 XLAT(V4L2_PIX_FMT_SGBRG12),
 #define XLAT_VAL_45 ((unsigned) (V4L2_PIX_FMT_SGBRG12))
 #define XLAT_STR_45 STRINGIFY(V4L2_PIX_FMT_SGBRG12)
 XLAT(V4L2_PIX_FMT_XBGR444),
 #define XLAT_VAL_46 ((unsigned) (V4L2_PIX_FMT_XBGR444))
 #define XLAT_STR_46 STRINGIFY(V4L2_PIX_FMT_XBGR444)
 XLAT(V4L2_PIX_FMT_SBGGR12),
 #define XLAT_VAL_47 ((unsigned) (V4L2_PIX_FMT_SBGGR12))
 #define XLAT_STR_47 STRINGIFY(V4L2_PIX_FMT_SBGGR12)
 XLAT(V4L2_PIX_FMT_SRGGB12),
 #define XLAT_VAL_48 ((unsigned) (V4L2_PIX_FMT_SRGGB12))
 #define XLAT_STR_48 STRINGIFY(V4L2_PIX_FMT_SRGGB12)
 XLAT(V4L2_PIX_FMT_NV12_16L16),
 #define XLAT_VAL_49 ((unsigned) (V4L2_PIX_FMT_NV12_16L16))
 #define XLAT_STR_49 STRINGIFY(V4L2_PIX_FMT_NV12_16L16)
 XLAT(V4L2_PIX_FMT_NV12M),
 #define XLAT_VAL_50 ((unsigned) (V4L2_PIX_FMT_NV12M))
 #define XLAT_STR_50 STRINGIFY(V4L2_PIX_FMT_NV12M)
 XLAT(V4L2_PIX_FMT_NV12MT),
 #define XLAT_VAL_51 ((unsigned) (V4L2_PIX_FMT_NV12MT))
 #define XLAT_STR_51 STRINGIFY(V4L2_PIX_FMT_NV12MT)
 XLAT(V4L2_PIX_FMT_NV12MT_16X16),
 #define XLAT_VAL_52 ((unsigned) (V4L2_PIX_FMT_NV12MT_16X16))
 #define XLAT_STR_52 STRINGIFY(V4L2_PIX_FMT_NV12MT_16X16)
 XLAT(V4L2_PIX_FMT_YUV420M),
 #define XLAT_VAL_53 ((unsigned) (V4L2_PIX_FMT_YUV420M))
 #define XLAT_STR_53 STRINGIFY(V4L2_PIX_FMT_YUV420M)
 XLAT(V4L2_PIX_FMT_ARGB444),
 #define XLAT_VAL_54 ((unsigned) (V4L2_PIX_FMT_ARGB444))
 #define XLAT_STR_54 STRINGIFY(V4L2_PIX_FMT_ARGB444)
 XLAT(V4L2_PIX_FMT_XRGB444),
 #define XLAT_VAL_55 ((unsigned) (V4L2_PIX_FMT_XRGB444))
 #define XLAT_STR_55 STRINGIFY(V4L2_PIX_FMT_XRGB444)
 XLAT(V4L2_PIX_FMT_NV12_32L32),
 #define XLAT_VAL_56 ((unsigned) (V4L2_PIX_FMT_NV12_32L32))
 #define XLAT_STR_56 STRINGIFY(V4L2_PIX_FMT_NV12_32L32)
 XLAT(V4L2_PIX_FMT_NV12_4L4),
 #define XLAT_VAL_57 ((unsigned) (V4L2_PIX_FMT_NV12_4L4))
 #define XLAT_STR_57 STRINGIFY(V4L2_PIX_FMT_NV12_4L4)
 XLAT(V4L2_PIX_FMT_YUV420),
 #define XLAT_VAL_58 ((unsigned) (V4L2_PIX_FMT_YUV420))
 #define XLAT_STR_58 STRINGIFY(V4L2_PIX_FMT_YUV420)
 XLAT(V4L2_PIX_FMT_NV12),
 #define XLAT_VAL_59 ((unsigned) (V4L2_PIX_FMT_NV12))
 #define XLAT_STR_59 STRINGIFY(V4L2_PIX_FMT_NV12)
 XLAT(V4L2_PIX_FMT_YVU420),
 #define XLAT_VAL_60 ((unsigned) (V4L2_PIX_FMT_YVU420))
 #define XLAT_STR_60 STRINGIFY(V4L2_PIX_FMT_YVU420)
 XLAT(V4L2_PIX_FMT_BGRX444),
 #define XLAT_VAL_61 ((unsigned) (V4L2_PIX_FMT_BGRX444))
 #define XLAT_STR_61 STRINGIFY(V4L2_PIX_FMT_BGRX444)
 XLAT(V4L2_PIX_FMT_RGBX444),
 #define XLAT_VAL_62 ((unsigned) (V4L2_PIX_FMT_RGBX444))
 #define XLAT_STR_62 STRINGIFY(V4L2_PIX_FMT_RGBX444)
 XLAT(V4L2_PIX_FMT_YVU444M),
 #define XLAT_VAL_63 ((unsigned) (V4L2_PIX_FMT_YVU444M))
 #define XLAT_STR_63 STRINGIFY(V4L2_PIX_FMT_YVU444M)
 XLAT(V4L2_PIX_FMT_NV42),
 #define XLAT_VAL_64 ((unsigned) (V4L2_PIX_FMT_NV42))
 #define XLAT_STR_64 STRINGIFY(V4L2_PIX_FMT_NV42)
 XLAT(V4L2_PIX_FMT_PWC2),
 #define XLAT_VAL_65 ((unsigned) (V4L2_PIX_FMT_PWC2))
 #define XLAT_STR_65 STRINGIFY(V4L2_PIX_FMT_PWC2)
 XLAT(V4L2_PIX_FMT_MPEG2),
 #define XLAT_VAL_66 ((unsigned) (V4L2_PIX_FMT_MPEG2))
 #define XLAT_STR_66 STRINGIFY(V4L2_PIX_FMT_MPEG2)
 XLAT(V4L2_PIX_FMT_SBGGR16),
 #define XLAT_VAL_67 ((unsigned) (V4L2_PIX_FMT_SBGGR16))
 #define XLAT_STR_67 STRINGIFY(V4L2_PIX_FMT_SBGGR16)
 XLAT(V4L2_PIX_FMT_H263),
 #define XLAT_VAL_68 ((unsigned) (V4L2_PIX_FMT_H263))
 #define XLAT_STR_68 STRINGIFY(V4L2_PIX_FMT_H263)
 XLAT(V4L2_PIX_FMT_RGB24),
 #define XLAT_VAL_69 ((unsigned) (V4L2_PIX_FMT_RGB24))
 #define XLAT_STR_69 STRINGIFY(V4L2_PIX_FMT_RGB24)
 XLAT(V4L2_PIX_FMT_BGR24),
 #define XLAT_VAL_70 ((unsigned) (V4L2_PIX_FMT_BGR24))
 #define XLAT_STR_70 STRINGIFY(V4L2_PIX_FMT_BGR24)
 XLAT(V4L2_PIX_FMT_HSV24),
 #define XLAT_VAL_71 ((unsigned) (V4L2_PIX_FMT_HSV24))
 #define XLAT_STR_71 STRINGIFY(V4L2_PIX_FMT_HSV24)
 XLAT(V4L2_PIX_FMT_YUV24),
 #define XLAT_VAL_72 ((unsigned) (V4L2_PIX_FMT_YUV24))
 #define XLAT_STR_72 STRINGIFY(V4L2_PIX_FMT_YUV24)
 XLAT(V4L2_PIX_FMT_SGBRG14),
 #define XLAT_VAL_73 ((unsigned) (V4L2_PIX_FMT_SGBRG14))
 #define XLAT_STR_73 STRINGIFY(V4L2_PIX_FMT_SGBRG14)
 XLAT(V4L2_PIX_FMT_SBGGR14),
 #define XLAT_VAL_74 ((unsigned) (V4L2_PIX_FMT_SBGGR14))
 #define XLAT_STR_74 STRINGIFY(V4L2_PIX_FMT_SBGGR14)
 XLAT(V4L2_PIX_FMT_SRGGB14),
 #define XLAT_VAL_75 ((unsigned) (V4L2_PIX_FMT_SRGGB14))
 #define XLAT_STR_75 STRINGIFY(V4L2_PIX_FMT_SRGGB14)
 XLAT(V4L2_PIX_FMT_SGRBG14),
 #define XLAT_VAL_76 ((unsigned) (V4L2_PIX_FMT_SGRBG14))
 #define XLAT_STR_76 STRINGIFY(V4L2_PIX_FMT_SGRBG14)
 XLAT(V4L2_PIX_FMT_ARGB32),
 #define XLAT_VAL_77 ((unsigned) (V4L2_PIX_FMT_ARGB32))
 #define XLAT_STR_77 STRINGIFY(V4L2_PIX_FMT_ARGB32)
 XLAT(V4L2_PIX_FMT_BGRA32),
 #define XLAT_VAL_78 ((unsigned) (V4L2_PIX_FMT_BGRA32))
 #define XLAT_STR_78 STRINGIFY(V4L2_PIX_FMT_BGRA32)
 XLAT(V4L2_PIX_FMT_RGBA32),
 #define XLAT_VAL_79 ((unsigned) (V4L2_PIX_FMT_RGBA32))
 #define XLAT_STR_79 STRINGIFY(V4L2_PIX_FMT_RGBA32)
 XLAT(V4L2_PIX_FMT_RGBX32),
 #define XLAT_VAL_80 ((unsigned) (V4L2_PIX_FMT_RGBX32))
 #define XLAT_STR_80 STRINGIFY(V4L2_PIX_FMT_RGBX32)
 XLAT(V4L2_PIX_FMT_HI240),
 #define XLAT_VAL_81 ((unsigned) (V4L2_PIX_FMT_HI240))
 #define XLAT_STR_81 STRINGIFY(V4L2_PIX_FMT_HI240)
 XLAT(V4L2_PIX_FMT_YUV444M),
 #define XLAT_VAL_82 ((unsigned) (V4L2_PIX_FMT_YUV444M))
 #define XLAT_STR_82 STRINGIFY(V4L2_PIX_FMT_YUV444M)
 XLAT(V4L2_PIX_FMT_ABGR32),
 #define XLAT_VAL_83 ((unsigned) (V4L2_PIX_FMT_ABGR32))
 #define XLAT_STR_83 STRINGIFY(V4L2_PIX_FMT_ABGR32)
 XLAT(V4L2_PIX_FMT_XBGR32),
 #define XLAT_VAL_84 ((unsigned) (V4L2_PIX_FMT_XBGR32))
 #define XLAT_STR_84 STRINGIFY(V4L2_PIX_FMT_XBGR32)
 XLAT(V4L2_PIX_FMT_NV24),
 #define XLAT_VAL_85 ((unsigned) (V4L2_PIX_FMT_NV24))
 #define XLAT_STR_85 STRINGIFY(V4L2_PIX_FMT_NV24)
 XLAT(V4L2_PIX_FMT_XRGB32),
 #define XLAT_VAL_86 ((unsigned) (V4L2_PIX_FMT_XRGB32))
 #define XLAT_STR_86 STRINGIFY(V4L2_PIX_FMT_XRGB32)
 XLAT(V4L2_PIX_FMT_BGRX32),
 #define XLAT_VAL_87 ((unsigned) (V4L2_PIX_FMT_BGRX32))
 #define XLAT_STR_87 STRINGIFY(V4L2_PIX_FMT_BGRX32)
 XLAT(V4L2_PIX_FMT_RGB444),
 #define XLAT_VAL_88 ((unsigned) (V4L2_PIX_FMT_RGB444))
 #define XLAT_STR_88 STRINGIFY(V4L2_PIX_FMT_RGB444)
 XLAT(V4L2_PIX_FMT_YUV444),
 #define XLAT_VAL_89 ((unsigned) (V4L2_PIX_FMT_YUV444))
 #define XLAT_STR_89 STRINGIFY(V4L2_PIX_FMT_YUV444)
 XLAT(V4L2_PIX_FMT_H264),
 #define XLAT_VAL_90 ((unsigned) (V4L2_PIX_FMT_H264))
 #define XLAT_STR_90 STRINGIFY(V4L2_PIX_FMT_H264)
 XLAT(V4L2_PIX_FMT_H264_MVC),
 #define XLAT_VAL_91 ((unsigned) (V4L2_PIX_FMT_H264_MVC))
 #define XLAT_STR_91 STRINGIFY(V4L2_PIX_FMT_H264_MVC)
 XLAT(V4L2_PIX_FMT_H264_SLICE),
 #define XLAT_VAL_92 ((unsigned) (V4L2_PIX_FMT_H264_SLICE))
 #define XLAT_STR_92 STRINGIFY(V4L2_PIX_FMT_H264_SLICE)
 XLAT(V4L2_PIX_FMT_RGB32),
 #define XLAT_VAL_93 ((unsigned) (V4L2_PIX_FMT_RGB32))
 #define XLAT_STR_93 STRINGIFY(V4L2_PIX_FMT_RGB32)
 XLAT(V4L2_PIX_FMT_CNF4),
 #define XLAT_VAL_94 ((unsigned) (V4L2_PIX_FMT_CNF4))
 #define XLAT_STR_94 STRINGIFY(V4L2_PIX_FMT_CNF4)
 XLAT(V4L2_PIX_FMT_MPEG4),
 #define XLAT_VAL_95 ((unsigned) (V4L2_PIX_FMT_MPEG4))
 #define XLAT_STR_95 STRINGIFY(V4L2_PIX_FMT_MPEG4)
 XLAT(V4L2_PIX_FMT_BGR32),
 #define XLAT_VAL_96 ((unsigned) (V4L2_PIX_FMT_BGR32))
 #define XLAT_STR_96 STRINGIFY(V4L2_PIX_FMT_BGR32)
 XLAT(V4L2_PIX_FMT_HSV32),
 #define XLAT_VAL_97 ((unsigned) (V4L2_PIX_FMT_HSV32))
 #define XLAT_STR_97 STRINGIFY(V4L2_PIX_FMT_HSV32)
 XLAT(V4L2_PIX_FMT_YUV32),
 #define XLAT_VAL_98 ((unsigned) (V4L2_PIX_FMT_YUV32))
 #define XLAT_STR_98 STRINGIFY(V4L2_PIX_FMT_YUV32)
 XLAT(V4L2_PIX_FMT_SPCA505),
 #define XLAT_VAL_99 ((unsigned) (V4L2_PIX_FMT_SPCA505))
 #define XLAT_STR_99 STRINGIFY(V4L2_PIX_FMT_SPCA505)
 XLAT(V4L2_PIX_FMT_BGRA555),
 #define XLAT_VAL_100 ((unsigned) (V4L2_PIX_FMT_BGRA555))
 #define XLAT_STR_100 STRINGIFY(V4L2_PIX_FMT_BGRA555)
 XLAT(V4L2_PIX_FMT_RGBA555),
 #define XLAT_VAL_101 ((unsigned) (V4L2_PIX_FMT_RGBA555))
 #define XLAT_STR_101 STRINGIFY(V4L2_PIX_FMT_RGBA555)
 XLAT(V4L2_PIX_FMT_ABGR555),
 #define XLAT_VAL_102 ((unsigned) (V4L2_PIX_FMT_ABGR555))
 #define XLAT_STR_102 STRINGIFY(V4L2_PIX_FMT_ABGR555)
 XLAT(V4L2_PIX_FMT_XBGR555),
 #define XLAT_VAL_103 ((unsigned) (V4L2_PIX_FMT_XBGR555))
 #define XLAT_STR_103 STRINGIFY(V4L2_PIX_FMT_XBGR555)
 XLAT(V4L2_PIX_FMT_ARGB555),
 #define XLAT_VAL_104 ((unsigned) (V4L2_PIX_FMT_ARGB555))
 #define XLAT_STR_104 STRINGIFY(V4L2_PIX_FMT_ARGB555)
 XLAT(V4L2_PIX_FMT_XRGB555),
 #define XLAT_VAL_105 ((unsigned) (V4L2_PIX_FMT_XRGB555))
 #define XLAT_STR_105 STRINGIFY(V4L2_PIX_FMT_XRGB555)
 XLAT(V4L2_PIX_FMT_BGRX555),
 #define XLAT_VAL_106 ((unsigned) (V4L2_PIX_FMT_BGRX555))
 #define XLAT_STR_106 STRINGIFY(V4L2_PIX_FMT_BGRX555)
 XLAT(V4L2_PIX_FMT_RGBX555),
 #define XLAT_VAL_107 ((unsigned) (V4L2_PIX_FMT_RGBX555))
 #define XLAT_STR_107 STRINGIFY(V4L2_PIX_FMT_RGBX555)
 XLAT(V4L2_PIX_FMT_ET61X251),
 #define XLAT_VAL_108 ((unsigned) (V4L2_PIX_FMT_ET61X251))
 #define XLAT_STR_108 STRINGIFY(V4L2_PIX_FMT_ET61X251)
 XLAT(V4L2_PIX_FMT_SGBRG16),
 #define XLAT_VAL_109 ((unsigned) (V4L2_PIX_FMT_SGBRG16))
 #define XLAT_STR_109 STRINGIFY(V4L2_PIX_FMT_SGBRG16)
 XLAT(V4L2_PIX_FMT_SRGGB16),
 #define XLAT_VAL_110 ((unsigned) (V4L2_PIX_FMT_SRGGB16))
 #define XLAT_STR_110 STRINGIFY(V4L2_PIX_FMT_SRGGB16)
 XLAT(V4L2_PIX_FMT_NV16M),
 #define XLAT_VAL_111 ((unsigned) (V4L2_PIX_FMT_NV16M))
 #define XLAT_STR_111 STRINGIFY(V4L2_PIX_FMT_NV16M)
 XLAT(V4L2_PIX_FMT_YUV422M),
 #define XLAT_VAL_112 ((unsigned) (V4L2_PIX_FMT_YUV422M))
 #define XLAT_STR_112 STRINGIFY(V4L2_PIX_FMT_YUV422M)
 XLAT(V4L2_PIX_FMT_SGRBG16),
 #define XLAT_VAL_113 ((unsigned) (V4L2_PIX_FMT_SGRBG16))
 #define XLAT_STR_113 STRINGIFY(V4L2_PIX_FMT_SGRBG16)
 XLAT(V4L2_PIX_FMT_NV16),
 #define XLAT_VAL_114 ((unsigned) (V4L2_PIX_FMT_NV16))
 #define XLAT_STR_114 STRINGIFY(V4L2_PIX_FMT_NV16)
 XLAT(V4L2_PIX_FMT_PAC207),
 #define XLAT_VAL_115 ((unsigned) (V4L2_PIX_FMT_PAC207))
 #define XLAT_STR_115 STRINGIFY(V4L2_PIX_FMT_PAC207)
 XLAT(V4L2_PIX_FMT_SPCA508),
 #define XLAT_VAL_116 ((unsigned) (V4L2_PIX_FMT_SPCA508))
 #define XLAT_STR_116 STRINGIFY(V4L2_PIX_FMT_SPCA508)
 XLAT(V4L2_PIX_FMT_OV518),
 #define XLAT_VAL_117 ((unsigned) (V4L2_PIX_FMT_OV518))
 #define XLAT_STR_117 STRINGIFY(V4L2_PIX_FMT_OV518)
 XLAT(V4L2_PIX_FMT_SBGGR10ALAW8),
 #define XLAT_VAL_118 ((unsigned) (V4L2_PIX_FMT_SBGGR10ALAW8))
 #define XLAT_STR_118 STRINGIFY(V4L2_PIX_FMT_SBGGR10ALAW8)
 XLAT(V4L2_PIX_FMT_SBGGR10DPCM8),
 #define XLAT_VAL_119 ((unsigned) (V4L2_PIX_FMT_SBGGR10DPCM8))
 #define XLAT_STR_119 STRINGIFY(V4L2_PIX_FMT_SBGGR10DPCM8)
 XLAT(V4L2_PIX_FMT_SGBRG10ALAW8),
 #define XLAT_VAL_120 ((unsigned) (V4L2_PIX_FMT_SGBRG10ALAW8))
 #define XLAT_STR_120 STRINGIFY(V4L2_PIX_FMT_SGBRG10ALAW8)
 XLAT(V4L2_PIX_FMT_SGBRG10DPCM8),
 #define XLAT_VAL_121 ((unsigned) (V4L2_PIX_FMT_SGBRG10DPCM8))
 #define XLAT_STR_121 STRINGIFY(V4L2_PIX_FMT_SGBRG10DPCM8)
 XLAT(V4L2_PIX_FMT_SRGGB10ALAW8),
 #define XLAT_VAL_122 ((unsigned) (V4L2_PIX_FMT_SRGGB10ALAW8))
 #define XLAT_STR_122 STRINGIFY(V4L2_PIX_FMT_SRGGB10ALAW8)
 XLAT(V4L2_PIX_FMT_SRGGB10DPCM8),
 #define XLAT_VAL_123 ((unsigned) (V4L2_PIX_FMT_SRGGB10DPCM8))
 #define XLAT_STR_123 STRINGIFY(V4L2_PIX_FMT_SRGGB10DPCM8)
 XLAT(V4L2_PIX_FMT_SGRBG10ALAW8),
 #define XLAT_VAL_124 ((unsigned) (V4L2_PIX_FMT_SGRBG10ALAW8))
 #define XLAT_STR_124 STRINGIFY(V4L2_PIX_FMT_SGRBG10ALAW8)
 XLAT(V4L2_PIX_FMT_PAL8),
 #define XLAT_VAL_125 ((unsigned) (V4L2_PIX_FMT_PAL8))
 #define XLAT_STR_125 STRINGIFY(V4L2_PIX_FMT_PAL8)
 XLAT(V4L2_PIX_FMT_YVU410),
 #define XLAT_VAL_126 ((unsigned) (V4L2_PIX_FMT_YVU410))
 #define XLAT_STR_126 STRINGIFY(V4L2_PIX_FMT_YVU410)
 XLAT(V4L2_PIX_FMT_YUV410),
 #define XLAT_VAL_127 ((unsigned) (V4L2_PIX_FMT_YUV410))
 #define XLAT_STR_127 STRINGIFY(V4L2_PIX_FMT_YUV410)
 XLAT(V4L2_PIX_FMT_SBGGR10P),
 #define XLAT_VAL_128 ((unsigned) (V4L2_PIX_FMT_SBGGR10P))
 #define XLAT_STR_128 STRINGIFY(V4L2_PIX_FMT_SBGGR10P)
 XLAT(V4L2_PIX_FMT_SGBRG10P),
 #define XLAT_VAL_129 ((unsigned) (V4L2_PIX_FMT_SGBRG10P))
 #define XLAT_STR_129 STRINGIFY(V4L2_PIX_FMT_SGBRG10P)
 XLAT(V4L2_PIX_FMT_SRGGB10P),
 #define XLAT_VAL_130 ((unsigned) (V4L2_PIX_FMT_SRGGB10P))
 #define XLAT_STR_130 STRINGIFY(V4L2_PIX_FMT_SRGGB10P)
 XLAT(V4L2_PIX_FMT_SGRBG10P),
 #define XLAT_VAL_131 ((unsigned) (V4L2_PIX_FMT_SGRBG10P))
 #define XLAT_STR_131 STRINGIFY(V4L2_PIX_FMT_SGRBG10P)
 XLAT(V4L2_PIX_FMT_CPIA1),
 #define XLAT_VAL_132 ((unsigned) (V4L2_PIX_FMT_CPIA1))
 #define XLAT_STR_132 STRINGIFY(V4L2_PIX_FMT_CPIA1)
 XLAT(V4L2_PIX_FMT_WNVA),
 #define XLAT_VAL_133 ((unsigned) (V4L2_PIX_FMT_WNVA))
 #define XLAT_STR_133 STRINGIFY(V4L2_PIX_FMT_WNVA)
 XLAT(V4L2_PIX_FMT_VUYA32),
 #define XLAT_VAL_134 ((unsigned) (V4L2_PIX_FMT_VUYA32))
 #define XLAT_STR_134 STRINGIFY(V4L2_PIX_FMT_VUYA32)
 XLAT(V4L2_PIX_FMT_Y10BPACK),
 #define XLAT_VAL_135 ((unsigned) (V4L2_PIX_FMT_Y10BPACK))
 #define XLAT_STR_135 STRINGIFY(V4L2_PIX_FMT_Y10BPACK)
 XLAT(V4L2_PIX_FMT_SRGGB8),
 #define XLAT_VAL_136 ((unsigned) (V4L2_PIX_FMT_SRGGB8))
 #define XLAT_STR_136 STRINGIFY(V4L2_PIX_FMT_SRGGB8)
 XLAT(V4L2_PIX_FMT_QC10C),
 #define XLAT_VAL_137 ((unsigned) (V4L2_PIX_FMT_QC10C))
 #define XLAT_STR_137 STRINGIFY(V4L2_PIX_FMT_QC10C)
 XLAT(V4L2_PIX_FMT_SQ905C),
 #define XLAT_VAL_138 ((unsigned) (V4L2_PIX_FMT_SQ905C))
 #define XLAT_STR_138 STRINGIFY(V4L2_PIX_FMT_SQ905C)
 XLAT(V4L2_PIX_FMT_QC08C),
 #define XLAT_VAL_139 ((unsigned) (V4L2_PIX_FMT_QC08C))
 #define XLAT_STR_139 STRINGIFY(V4L2_PIX_FMT_QC08C)
 XLAT(V4L2_PIX_FMT_SBGGR12P),
 #define XLAT_VAL_140 ((unsigned) (V4L2_PIX_FMT_SBGGR12P))
 #define XLAT_STR_140 STRINGIFY(V4L2_PIX_FMT_SBGGR12P)
 XLAT(V4L2_PIX_FMT_SGBRG12P),
 #define XLAT_VAL_141 ((unsigned) (V4L2_PIX_FMT_SGBRG12P))
 #define XLAT_STR_141 STRINGIFY(V4L2_PIX_FMT_SGBRG12P)
 XLAT(V4L2_PIX_FMT_SRGGB12P),
 #define XLAT_VAL_142 ((unsigned) (V4L2_PIX_FMT_SRGGB12P))
 #define XLAT_STR_142 STRINGIFY(V4L2_PIX_FMT_SRGGB12P)
 XLAT(V4L2_PIX_FMT_SGRBG12P),
 #define XLAT_VAL_143 ((unsigned) (V4L2_PIX_FMT_SGRBG12P))
 #define XLAT_STR_143 STRINGIFY(V4L2_PIX_FMT_SGRBG12P)
 XLAT(V4L2_PIX_FMT_HEVC),
 #define XLAT_VAL_144 ((unsigned) (V4L2_PIX_FMT_HEVC))
 #define XLAT_STR_144 STRINGIFY(V4L2_PIX_FMT_HEVC)
 XLAT(V4L2_PIX_FMT_XVID),
 #define XLAT_VAL_145 ((unsigned) (V4L2_PIX_FMT_XVID))
 #define XLAT_STR_145 STRINGIFY(V4L2_PIX_FMT_XVID)
 XLAT(V4L2_PIX_FMT_SBGGR14P),
 #define XLAT_VAL_146 ((unsigned) (V4L2_PIX_FMT_SBGGR14P))
 #define XLAT_STR_146 STRINGIFY(V4L2_PIX_FMT_SBGGR14P)
 XLAT(V4L2_PIX_FMT_SGBRG14P),
 #define XLAT_VAL_147 ((unsigned) (V4L2_PIX_FMT_SGBRG14P))
 #define XLAT_STR_147 STRINGIFY(V4L2_PIX_FMT_SGBRG14P)
 XLAT(V4L2_PIX_FMT_SRGGB14P),
 #define XLAT_VAL_148 ((unsigned) (V4L2_PIX_FMT_SRGGB14P))
 #define XLAT_STR_148 STRINGIFY(V4L2_PIX_FMT_SRGGB14P)
 XLAT(V4L2_PIX_FMT_SGRBG14P),
 #define XLAT_VAL_149 ((unsigned) (V4L2_PIX_FMT_SGRBG14P))
 #define XLAT_STR_149 STRINGIFY(V4L2_PIX_FMT_SGRBG14P)
 XLAT(V4L2_PIX_FMT_VP8_FRAME),
 #define XLAT_VAL_150 ((unsigned) (V4L2_PIX_FMT_VP8_FRAME))
 #define XLAT_STR_150 STRINGIFY(V4L2_PIX_FMT_VP8_FRAME)
 XLAT(V4L2_PIX_FMT_VP9_FRAME),
 #define XLAT_VAL_151 ((unsigned) (V4L2_PIX_FMT_VP9_FRAME))
 #define XLAT_STR_151 STRINGIFY(V4L2_PIX_FMT_VP9_FRAME)
 XLAT(V4L2_PIX_FMT_VC1_ANNEX_G),
 #define XLAT_VAL_152 ((unsigned) (V4L2_PIX_FMT_VC1_ANNEX_G))
 #define XLAT_STR_152 STRINGIFY(V4L2_PIX_FMT_VC1_ANNEX_G)
 XLAT(V4L2_PIX_FMT_IPU3_SGRBG10),
 #define XLAT_VAL_153 ((unsigned) (V4L2_PIX_FMT_IPU3_SGRBG10))
 #define XLAT_STR_153 STRINGIFY(V4L2_PIX_FMT_IPU3_SGRBG10)
 XLAT(V4L2_PIX_FMT_SGRBG8),
 #define XLAT_VAL_154 ((unsigned) (V4L2_PIX_FMT_SGRBG8))
 #define XLAT_STR_154 STRINGIFY(V4L2_PIX_FMT_SGRBG8)
 XLAT(V4L2_PIX_FMT_JPEG),
 #define XLAT_VAL_155 ((unsigned) (V4L2_PIX_FMT_JPEG))
 #define XLAT_STR_155 STRINGIFY(V4L2_PIX_FMT_JPEG)
 XLAT(V4L2_PIX_FMT_MPEG),
 #define XLAT_VAL_156 ((unsigned) (V4L2_PIX_FMT_MPEG))
 #define XLAT_STR_156 STRINGIFY(V4L2_PIX_FMT_MPEG)
 XLAT(V4L2_PIX_FMT_MJPEG),
 #define XLAT_VAL_157 ((unsigned) (V4L2_PIX_FMT_MJPEG))
 #define XLAT_STR_157 STRINGIFY(V4L2_PIX_FMT_MJPEG)
 XLAT(V4L2_PIX_FMT_PJPG),
 #define XLAT_VAL_158 ((unsigned) (V4L2_PIX_FMT_PJPG))
 #define XLAT_STR_158 STRINGIFY(V4L2_PIX_FMT_PJPG)
 XLAT(V4L2_PIX_FMT_SGBRG8),
 #define XLAT_VAL_159 ((unsigned) (V4L2_PIX_FMT_SGBRG8))
 #define XLAT_STR_159 STRINGIFY(V4L2_PIX_FMT_SGBRG8)
 XLAT(V4L2_PIX_FMT_BGR666),
 #define XLAT_VAL_160 ((unsigned) (V4L2_PIX_FMT_BGR666))
 #define XLAT_STR_160 STRINGIFY(V4L2_PIX_FMT_BGR666)
 XLAT(V4L2_PIX_FMT_FWHT_STATELESS),
 #define XLAT_VAL_161 ((unsigned) (V4L2_PIX_FMT_FWHT_STATELESS))
 #define XLAT_STR_161 STRINGIFY(V4L2_PIX_FMT_FWHT_STATELESS)
 XLAT(V4L2_PIX_FMT_Y12I),
 #define XLAT_VAL_162 ((unsigned) (V4L2_PIX_FMT_Y12I))
 #define XLAT_STR_162 STRINGIFY(V4L2_PIX_FMT_Y12I)
 XLAT(V4L2_PIX_FMT_S5C_UYVY_JPG),
 #define XLAT_VAL_163 ((unsigned) (V4L2_PIX_FMT_S5C_UYVY_JPG))
 #define XLAT_STR_163 STRINGIFY(V4L2_PIX_FMT_S5C_UYVY_JPG)
 XLAT(V4L2_PIX_FMT_KONICA420),
 #define XLAT_VAL_164 ((unsigned) (V4L2_PIX_FMT_KONICA420))
 #define XLAT_STR_164 STRINGIFY(V4L2_PIX_FMT_KONICA420)
 XLAT(V4L2_PIX_FMT_INZI),
 #define XLAT_VAL_165 ((unsigned) (V4L2_PIX_FMT_INZI))
 #define XLAT_STR_165 STRINGIFY(V4L2_PIX_FMT_INZI)
 XLAT(V4L2_PIX_FMT_VC1_ANNEX_L),
 #define XLAT_VAL_166 ((unsigned) (V4L2_PIX_FMT_VC1_ANNEX_L))
 #define XLAT_STR_166 STRINGIFY(V4L2_PIX_FMT_VC1_ANNEX_L)
 XLAT(V4L2_PIX_FMT_JPGL),
 #define XLAT_VAL_167 ((unsigned) (V4L2_PIX_FMT_JPGL))
 #define XLAT_STR_167 STRINGIFY(V4L2_PIX_FMT_JPGL)
 XLAT(V4L2_PIX_FMT_RGB555),
 #define XLAT_VAL_168 ((unsigned) (V4L2_PIX_FMT_RGB555))
 #define XLAT_STR_168 STRINGIFY(V4L2_PIX_FMT_RGB555)
 XLAT(V4L2_PIX_FMT_YUV555),
 #define XLAT_VAL_169 ((unsigned) (V4L2_PIX_FMT_YUV555))
 #define XLAT_STR_169 STRINGIFY(V4L2_PIX_FMT_YUV555)
 XLAT(V4L2_PIX_FMT_Y10P),
 #define XLAT_VAL_170 ((unsigned) (V4L2_PIX_FMT_Y10P))
 #define XLAT_STR_170 STRINGIFY(V4L2_PIX_FMT_Y10P)
 XLAT(V4L2_PIX_FMT_YUV411P),
 #define XLAT_VAL_171 ((unsigned) (V4L2_PIX_FMT_YUV411P))
 #define XLAT_STR_171 STRINGIFY(V4L2_PIX_FMT_YUV411P)
 XLAT(V4L2_PIX_FMT_Y41P),
 #define XLAT_VAL_172 ((unsigned) (V4L2_PIX_FMT_Y41P))
 #define XLAT_STR_172 STRINGIFY(V4L2_PIX_FMT_Y41P)
 XLAT(V4L2_PIX_FMT_YUV422P),
 #define XLAT_VAL_173 ((unsigned) (V4L2_PIX_FMT_YUV422P))
 #define XLAT_STR_173 STRINGIFY(V4L2_PIX_FMT_YUV422P)
 XLAT(V4L2_PIX_FMT_RGB565),
 #define XLAT_VAL_174 ((unsigned) (V4L2_PIX_FMT_RGB565))
 #define XLAT_STR_174 STRINGIFY(V4L2_PIX_FMT_RGB565)
 XLAT(V4L2_PIX_FMT_YUV565),
 #define XLAT_VAL_175 ((unsigned) (V4L2_PIX_FMT_YUV565))
 #define XLAT_STR_175 STRINGIFY(V4L2_PIX_FMT_YUV565)
 XLAT(V4L2_PIX_FMT_RGB555X),
 #define XLAT_VAL_176 ((unsigned) (V4L2_PIX_FMT_RGB555X))
 #define XLAT_STR_176 STRINGIFY(V4L2_PIX_FMT_RGB555X)
 XLAT(V4L2_PIX_FMT_RGB565X),
 #define XLAT_VAL_177 ((unsigned) (V4L2_PIX_FMT_RGB565X))
 #define XLAT_STR_177 STRINGIFY(V4L2_PIX_FMT_RGB565X)
 XLAT(V4L2_PIX_FMT_MPEG2_SLICE),
 #define XLAT_VAL_178 ((unsigned) (V4L2_PIX_FMT_MPEG2_SLICE))
 #define XLAT_STR_178 STRINGIFY(V4L2_PIX_FMT_MPEG2_SLICE)
 XLAT(V4L2_PIX_FMT_FWHT),
 #define XLAT_VAL_179 ((unsigned) (V4L2_PIX_FMT_FWHT))
 #define XLAT_STR_179 STRINGIFY(V4L2_PIX_FMT_FWHT)
 XLAT(V4L2_PIX_FMT_YVYU),
 #define XLAT_VAL_180 ((unsigned) (V4L2_PIX_FMT_YVYU))
 #define XLAT_STR_180 STRINGIFY(V4L2_PIX_FMT_YVYU)
 XLAT(V4L2_PIX_FMT_CIT_YYVYUY),
 #define XLAT_VAL_181 ((unsigned) (V4L2_PIX_FMT_CIT_YYVYUY))
 #define XLAT_STR_181 STRINGIFY(V4L2_PIX_FMT_CIT_YYVYUY)
 XLAT(V4L2_PIX_FMT_AYUV32),
 #define XLAT_VAL_182 ((unsigned) (V4L2_PIX_FMT_AYUV32))
 #define XLAT_STR_182 STRINGIFY(V4L2_PIX_FMT_AYUV32)
 XLAT(V4L2_PIX_FMT_XYUV32),
 #define XLAT_VAL_183 ((unsigned) (V4L2_PIX_FMT_XYUV32))
 #define XLAT_STR_183 STRINGIFY(V4L2_PIX_FMT_XYUV32)
 XLAT(V4L2_PIX_FMT_YYUV),
 #define XLAT_VAL_184 ((unsigned) (V4L2_PIX_FMT_YYUV))
 #define XLAT_STR_184 STRINGIFY(V4L2_PIX_FMT_YYUV)
 XLAT(V4L2_PIX_FMT_YUYV),
 #define XLAT_VAL_185 ((unsigned) (V4L2_PIX_FMT_YUYV))
 #define XLAT_STR_185 STRINGIFY(V4L2_PIX_FMT_YUYV)
 XLAT(V4L2_PIX_FMT_SN9C2028),
 #define XLAT_VAL_186 ((unsigned) (V4L2_PIX_FMT_SN9C2028))
 #define XLAT_STR_186 STRINGIFY(V4L2_PIX_FMT_SN9C2028)
 XLAT(V4L2_PIX_FMT_VUYX32),
 #define XLAT_VAL_187 ((unsigned) (V4L2_PIX_FMT_VUYX32))
 #define XLAT_STR_187 STRINGIFY(V4L2_PIX_FMT_VUYX32)
 XLAT(V4L2_PIX_FMT_GREY),
 #define XLAT_VAL_188 ((unsigned) (V4L2_PIX_FMT_GREY))
 #define XLAT_STR_188 STRINGIFY(V4L2_PIX_FMT_GREY)
 XLAT(V4L2_PIX_FMT_VYUY),
 #define XLAT_VAL_189 ((unsigned) (V4L2_PIX_FMT_VYUY))
 #define XLAT_STR_189 STRINGIFY(V4L2_PIX_FMT_VYUY)
 XLAT(V4L2_PIX_FMT_UYVY),
 #define XLAT_VAL_190 ((unsigned) (V4L2_PIX_FMT_UYVY))
 #define XLAT_STR_190 STRINGIFY(V4L2_PIX_FMT_UYVY)
 XLAT(V4L2_PIX_FMT_IPU3_SBGGR10),
 #define XLAT_VAL_191 ((unsigned) (V4L2_PIX_FMT_IPU3_SBGGR10))
 #define XLAT_STR_191 STRINGIFY(V4L2_PIX_FMT_IPU3_SBGGR10)
 XLAT(V4L2_PIX_FMT_DV),
 #define XLAT_VAL_192 ((unsigned) (V4L2_PIX_FMT_DV))
 #define XLAT_STR_192 STRINGIFY(V4L2_PIX_FMT_DV)
 XLAT(V4L2_PIX_FMT_IPU3_SGBRG10),
 #define XLAT_VAL_193 ((unsigned) (V4L2_PIX_FMT_IPU3_SGBRG10))
 #define XLAT_STR_193 STRINGIFY(V4L2_PIX_FMT_IPU3_SGBRG10)
 XLAT(V4L2_PIX_FMT_IPU3_SRGGB10),
 #define XLAT_VAL_194 ((unsigned) (V4L2_PIX_FMT_IPU3_SRGGB10))
 #define XLAT_STR_194 STRINGIFY(V4L2_PIX_FMT_IPU3_SRGGB10)
 XLAT(V4L2_PIX_FMT_IPU3_Y10),
 #define XLAT_VAL_195 ((unsigned) (V4L2_PIX_FMT_IPU3_Y10))
 #define XLAT_STR_195 STRINGIFY(V4L2_PIX_FMT_IPU3_Y10)
 XLAT(V4L2_PIX_FMT_Y16_BE),
 #define XLAT_VAL_196 ((unsigned) (V4L2_PIX_FMT_Y16_BE))
 #define XLAT_STR_196 STRINGIFY(V4L2_PIX_FMT_Y16_BE)
 XLAT(V4L2_PIX_FMT_NV12M_10BE_8L128),
 #define XLAT_VAL_197 ((unsigned) (V4L2_PIX_FMT_NV12M_10BE_8L128))
 #define XLAT_STR_197 STRINGIFY(V4L2_PIX_FMT_NV12M_10BE_8L128)
 XLAT(V4L2_PIX_FMT_ARGB555X),
 #define XLAT_VAL_198 ((unsigned) (V4L2_PIX_FMT_ARGB555X))
 #define XLAT_STR_198 STRINGIFY(V4L2_PIX_FMT_ARGB555X)
 XLAT(V4L2_PIX_FMT_XRGB555X),
 #define XLAT_VAL_199 ((unsigned) (V4L2_PIX_FMT_XRGB555X))
 #define XLAT_STR_199 STRINGIFY(V4L2_PIX_FMT_XRGB555X)
};
#  if !(defined HAVE_M32_MPERS || defined HAVE_MX32_MPERS)
static
#  endif
const struct xlat v4l2_pix_fmts[1] = { {
 .data = v4l2_pix_fmts_xdata,
 .size = ARRAY_SIZE(v4l2_pix_fmts_xdata),
 .type = XT_SORTED,
 .flags_mask = 0
#  ifdef XLAT_VAL_0
  | XLAT_VAL_0
#  endif
#  ifdef XLAT_VAL_1
  | XLAT_VAL_1
#  endif
#  ifdef XLAT_VAL_2
  | XLAT_VAL_2
#  endif
#  ifdef XLAT_VAL_3
  | XLAT_VAL_3
#  endif
#  ifdef XLAT_VAL_4
  | XLAT_VAL_4
#  endif
#  ifdef XLAT_VAL_5
  | XLAT_VAL_5
#  endif
#  ifdef XLAT_VAL_6
  | XLAT_VAL_6
#  endif
#  ifdef XLAT_VAL_7
  | XLAT_VAL_7
#  endif
#  ifdef XLAT_VAL_8
  | XLAT_VAL_8
#  endif
#  ifdef XLAT_VAL_9
  | XLAT_VAL_9
#  endif
#  ifdef XLAT_VAL_10
  | XLAT_VAL_10
#  endif
#  ifdef XLAT_VAL_11
  | XLAT_VAL_11
#  endif
#  ifdef XLAT_VAL_12
  | XLAT_VAL_12
#  endif
#  ifdef XLAT_VAL_13
  | XLAT_VAL_13
#  endif
#  ifdef XLAT_VAL_14
  | XLAT_VAL_14
#  endif
#  ifdef XLAT_VAL_15
  | XLAT_VAL_15
#  endif
#  ifdef XLAT_VAL_16
  | XLAT_VAL_16
#  endif
#  ifdef XLAT_VAL_17
  | XLAT_VAL_17
#  endif
#  ifdef XLAT_VAL_18
  | XLAT_VAL_18
#  endif
#  ifdef XLAT_VAL_19
  | XLAT_VAL_19
#  endif
#  ifdef XLAT_VAL_20
  | XLAT_VAL_20
#  endif
#  ifdef XLAT_VAL_21
  | XLAT_VAL_21
#  endif
#  ifdef XLAT_VAL_22
  | XLAT_VAL_22
#  endif
#  ifdef XLAT_VAL_23
  | XLAT_VAL_23
#  endif
#  ifdef XLAT_VAL_24
  | XLAT_VAL_24
#  endif
#  ifdef XLAT_VAL_25
  | XLAT_VAL_25
#  endif
#  ifdef XLAT_VAL_26
  | XLAT_VAL_26
#  endif
#  ifdef XLAT_VAL_27
  | XLAT_VAL_27
#  endif
#  ifdef XLAT_VAL_28
  | XLAT_VAL_28
#  endif
#  ifdef XLAT_VAL_29
  | XLAT_VAL_29
#  endif
#  ifdef XLAT_VAL_30
  | XLAT_VAL_30
#  endif
#  ifdef XLAT_VAL_31
  | XLAT_VAL_31
#  endif
#  ifdef XLAT_VAL_32
  | XLAT_VAL_32
#  endif
#  ifdef XLAT_VAL_33
  | XLAT_VAL_33
#  endif
#  ifdef XLAT_VAL_34
  | XLAT_VAL_34
#  endif
#  ifdef XLAT_VAL_35
  | XLAT_VAL_35
#  endif
#  ifdef XLAT_VAL_36
  | XLAT_VAL_36
#  endif
#  ifdef XLAT_VAL_37
  | XLAT_VAL_37
#  endif
#  ifdef XLAT_VAL_38
  | XLAT_VAL_38
#  endif
#  ifdef XLAT_VAL_39
  | XLAT_VAL_39
#  endif
#  ifdef XLAT_VAL_40
  | XLAT_VAL_40
#  endif
#  ifdef XLAT_VAL_41
  | XLAT_VAL_41
#  endif
#  ifdef XLAT_VAL_42
  | XLAT_VAL_42
#  endif
#  ifdef XLAT_VAL_43
  | XLAT_VAL_43
#  endif
#  ifdef XLAT_VAL_44
  | XLAT_VAL_44
#  endif
#  ifdef XLAT_VAL_45
  | XLAT_VAL_45
#  endif
#  ifdef XLAT_VAL_46
  | XLAT_VAL_46
#  endif
#  ifdef XLAT_VAL_47
  | XLAT_VAL_47
#  endif
#  ifdef XLAT_VAL_48
  | XLAT_VAL_48
#  endif
#  ifdef XLAT_VAL_49
  | XLAT_VAL_49
#  endif
#  ifdef XLAT_VAL_50
  | XLAT_VAL_50
#  endif
#  ifdef XLAT_VAL_51
  | XLAT_VAL_51
#  endif
#  ifdef XLAT_VAL_52
  | XLAT_VAL_52
#  endif
#  ifdef XLAT_VAL_53
  | XLAT_VAL_53
#  endif
#  ifdef XLAT_VAL_54
  | XLAT_VAL_54
#  endif
#  ifdef XLAT_VAL_55
  | XLAT_VAL_55
#  endif
#  ifdef XLAT_VAL_56
  | XLAT_VAL_56
#  endif
#  ifdef XLAT_VAL_57
  | XLAT_VAL_57
#  endif
#  ifdef XLAT_VAL_58
  | XLAT_VAL_58
#  endif
#  ifdef XLAT_VAL_59
  | XLAT_VAL_59
#  endif
#  ifdef XLAT_VAL_60
  | XLAT_VAL_60
#  endif
#  ifdef XLAT_VAL_61
  | XLAT_VAL_61
#  endif
#  ifdef XLAT_VAL_62
  | XLAT_VAL_62
#  endif
#  ifdef XLAT_VAL_63
  | XLAT_VAL_63
#  endif
#  ifdef XLAT_VAL_64
  | XLAT_VAL_64
#  endif
#  ifdef XLAT_VAL_65
  | XLAT_VAL_65
#  endif
#  ifdef XLAT_VAL_66
  | XLAT_VAL_66
#  endif
#  ifdef XLAT_VAL_67
  | XLAT_VAL_67
#  endif
#  ifdef XLAT_VAL_68
  | XLAT_VAL_68
#  endif
#  ifdef XLAT_VAL_69
  | XLAT_VAL_69
#  endif
#  ifdef XLAT_VAL_70
  | XLAT_VAL_70
#  endif
#  ifdef XLAT_VAL_71
  | XLAT_VAL_71
#  endif
#  ifdef XLAT_VAL_72
  | XLAT_VAL_72
#  endif
#  ifdef XLAT_VAL_73
  | XLAT_VAL_73
#  endif
#  ifdef XLAT_VAL_74
  | XLAT_VAL_74
#  endif
#  ifdef XLAT_VAL_75
  | XLAT_VAL_75
#  endif
#  ifdef XLAT_VAL_76
  | XLAT_VAL_76
#  endif
#  ifdef XLAT_VAL_77
  | XLAT_VAL_77
#  endif
#  ifdef XLAT_VAL_78
  | XLAT_VAL_78
#  endif
#  ifdef XLAT_VAL_79
  | XLAT_VAL_79
#  endif
#  ifdef XLAT_VAL_80
  | XLAT_VAL_80
#  endif
#  ifdef XLAT_VAL_81
  | XLAT_VAL_81
#  endif
#  ifdef XLAT_VAL_82
  | XLAT_VAL_82
#  endif
#  ifdef XLAT_VAL_83
  | XLAT_VAL_83
#  endif
#  ifdef XLAT_VAL_84
  | XLAT_VAL_84
#  endif
#  ifdef XLAT_VAL_85
  | XLAT_VAL_85
#  endif
#  ifdef XLAT_VAL_86
  | XLAT_VAL_86
#  endif
#  ifdef XLAT_VAL_87
  | XLAT_VAL_87
#  endif
#  ifdef XLAT_VAL_88
  | XLAT_VAL_88
#  endif
#  ifdef XLAT_VAL_89
  | XLAT_VAL_89
#  endif
#  ifdef XLAT_VAL_90
  | XLAT_VAL_90
#  endif
#  ifdef XLAT_VAL_91
  | XLAT_VAL_91
#  endif
#  ifdef XLAT_VAL_92
  | XLAT_VAL_92
#  endif
#  ifdef XLAT_VAL_93
  | XLAT_VAL_93
#  endif
#  ifdef XLAT_VAL_94
  | XLAT_VAL_94
#  endif
#  ifdef XLAT_VAL_95
  | XLAT_VAL_95
#  endif
#  ifdef XLAT_VAL_96
  | XLAT_VAL_96
#  endif
#  ifdef XLAT_VAL_97
  | XLAT_VAL_97
#  endif
#  ifdef XLAT_VAL_98
  | XLAT_VAL_98
#  endif
#  ifdef XLAT_VAL_99
  | XLAT_VAL_99
#  endif
#  ifdef XLAT_VAL_100
  | XLAT_VAL_100
#  endif
#  ifdef XLAT_VAL_101
  | XLAT_VAL_101
#  endif
#  ifdef XLAT_VAL_102
  | XLAT_VAL_102
#  endif
#  ifdef XLAT_VAL_103
  | XLAT_VAL_103
#  endif
#  ifdef XLAT_VAL_104
  | XLAT_VAL_104
#  endif
#  ifdef XLAT_VAL_105
  | XLAT_VAL_105
#  endif
#  ifdef XLAT_VAL_106
  | XLAT_VAL_106
#  endif
#  ifdef XLAT_VAL_107
  | XLAT_VAL_107
#  endif
#  ifdef XLAT_VAL_108
  | XLAT_VAL_108
#  endif
#  ifdef XLAT_VAL_109
  | XLAT_VAL_109
#  endif
#  ifdef XLAT_VAL_110
  | XLAT_VAL_110
#  endif
#  ifdef XLAT_VAL_111
  | XLAT_VAL_111
#  endif
#  ifdef XLAT_VAL_112
  | XLAT_VAL_112
#  endif
#  ifdef XLAT_VAL_113
  | XLAT_VAL_113
#  endif
#  ifdef XLAT_VAL_114
  | XLAT_VAL_114
#  endif
#  ifdef XLAT_VAL_115
  | XLAT_VAL_115
#  endif
#  ifdef XLAT_VAL_116
  | XLAT_VAL_116
#  endif
#  ifdef XLAT_VAL_117
  | XLAT_VAL_117
#  endif
#  ifdef XLAT_VAL_118
  | XLAT_VAL_118
#  endif
#  ifdef XLAT_VAL_119
  | XLAT_VAL_119
#  endif
#  ifdef XLAT_VAL_120
  | XLAT_VAL_120
#  endif
#  ifdef XLAT_VAL_121
  | XLAT_VAL_121
#  endif
#  ifdef XLAT_VAL_122
  | XLAT_VAL_122
#  endif
#  ifdef XLAT_VAL_123
  | XLAT_VAL_123
#  endif
#  ifdef XLAT_VAL_124
  | XLAT_VAL_124
#  endif
#  ifdef XLAT_VAL_125
  | XLAT_VAL_125
#  endif
#  ifdef XLAT_VAL_126
  | XLAT_VAL_126
#  endif
#  ifdef XLAT_VAL_127
  | XLAT_VAL_127
#  endif
#  ifdef XLAT_VAL_128
  | XLAT_VAL_128
#  endif
#  ifdef XLAT_VAL_129
  | XLAT_VAL_129
#  endif
#  ifdef XLAT_VAL_130
  | XLAT_VAL_130
#  endif
#  ifdef XLAT_VAL_131
  | XLAT_VAL_131
#  endif
#  ifdef XLAT_VAL_132
  | XLAT_VAL_132
#  endif
#  ifdef XLAT_VAL_133
  | XLAT_VAL_133
#  endif
#  ifdef XLAT_VAL_134
  | XLAT_VAL_134
#  endif
#  ifdef XLAT_VAL_135
  | XLAT_VAL_135
#  endif
#  ifdef XLAT_VAL_136
  | XLAT_VAL_136
#  endif
#  ifdef XLAT_VAL_137
  | XLAT_VAL_137
#  endif
#  ifdef XLAT_VAL_138
  | XLAT_VAL_138
#  endif
#  ifdef XLAT_VAL_139
  | XLAT_VAL_139
#  endif
#  ifdef XLAT_VAL_140
  | XLAT_VAL_140
#  endif
#  ifdef XLAT_VAL_141
  | XLAT_VAL_141
#  endif
#  ifdef XLAT_VAL_142
  | XLAT_VAL_142
#  endif
#  ifdef XLAT_VAL_143
  | XLAT_VAL_143
#  endif
#  ifdef XLAT_VAL_144
  | XLAT_VAL_144
#  endif
#  ifdef XLAT_VAL_145
  | XLAT_VAL_145
#  endif
#  ifdef XLAT_VAL_146
  | XLAT_VAL_146
#  endif
#  ifdef XLAT_VAL_147
  | XLAT_VAL_147
#  endif
#  ifdef XLAT_VAL_148
  | XLAT_VAL_148
#  endif
#  ifdef XLAT_VAL_149
  | XLAT_VAL_149
#  endif
#  ifdef XLAT_VAL_150
  | XLAT_VAL_150
#  endif
#  ifdef XLAT_VAL_151
  | XLAT_VAL_151
#  endif
#  ifdef XLAT_VAL_152
  | XLAT_VAL_152
#  endif
#  ifdef XLAT_VAL_153
  | XLAT_VAL_153
#  endif
#  ifdef XLAT_VAL_154
  | XLAT_VAL_154
#  endif
#  ifdef XLAT_VAL_155
  | XLAT_VAL_155
#  endif
#  ifdef XLAT_VAL_156
  | XLAT_VAL_156
#  endif
#  ifdef XLAT_VAL_157
  | XLAT_VAL_157
#  endif
#  ifdef XLAT_VAL_158
  | XLAT_VAL_158
#  endif
#  ifdef XLAT_VAL_159
  | XLAT_VAL_159
#  endif
#  ifdef XLAT_VAL_160
  | XLAT_VAL_160
#  endif
#  ifdef XLAT_VAL_161
  | XLAT_VAL_161
#  endif
#  ifdef XLAT_VAL_162
  | XLAT_VAL_162
#  endif
#  ifdef XLAT_VAL_163
  | XLAT_VAL_163
#  endif
#  ifdef XLAT_VAL_164
  | XLAT_VAL_164
#  endif
#  ifdef XLAT_VAL_165
  | XLAT_VAL_165
#  endif
#  ifdef XLAT_VAL_166
  | XLAT_VAL_166
#  endif
#  ifdef XLAT_VAL_167
  | XLAT_VAL_167
#  endif
#  ifdef XLAT_VAL_168
  | XLAT_VAL_168
#  endif
#  ifdef XLAT_VAL_169
  | XLAT_VAL_169
#  endif
#  ifdef XLAT_VAL_170
  | XLAT_VAL_170
#  endif
#  ifdef XLAT_VAL_171
  | XLAT_VAL_171
#  endif
#  ifdef XLAT_VAL_172
  | XLAT_VAL_172
#  endif
#  ifdef XLAT_VAL_173
  | XLAT_VAL_173
#  endif
#  ifdef XLAT_VAL_174
  | XLAT_VAL_174
#  endif
#  ifdef XLAT_VAL_175
  | XLAT_VAL_175
#  endif
#  ifdef XLAT_VAL_176
  | XLAT_VAL_176
#  endif
#  ifdef XLAT_VAL_177
  | XLAT_VAL_177
#  endif
#  ifdef XLAT_VAL_178
  | XLAT_VAL_178
#  endif
#  ifdef XLAT_VAL_179
  | XLAT_VAL_179
#  endif
#  ifdef XLAT_VAL_180
  | XLAT_VAL_180
#  endif
#  ifdef XLAT_VAL_181
  | XLAT_VAL_181
#  endif
#  ifdef XLAT_VAL_182
  | XLAT_VAL_182
#  endif
#  ifdef XLAT_VAL_183
  | XLAT_VAL_183
#  endif
#  ifdef XLAT_VAL_184
  | XLAT_VAL_184
#  endif
#  ifdef XLAT_VAL_185
  | XLAT_VAL_185
#  endif
#  ifdef XLAT_VAL_186
  | XLAT_VAL_186
#  endif
#  ifdef XLAT_VAL_187
  | XLAT_VAL_187
#  endif
#  ifdef XLAT_VAL_188
  | XLAT_VAL_188
#  endif
#  ifdef XLAT_VAL_189
  | XLAT_VAL_189
#  endif
#  ifdef XLAT_VAL_190
  | XLAT_VAL_190
#  endif
#  ifdef XLAT_VAL_191
  | XLAT_VAL_191
#  endif
#  ifdef XLAT_VAL_192
  | XLAT_VAL_192
#  endif
#  ifdef XLAT_VAL_193
  | XLAT_VAL_193
#  endif
#  ifdef XLAT_VAL_194
  | XLAT_VAL_194
#  endif
#  ifdef XLAT_VAL_195
  | XLAT_VAL_195
#  endif
#  ifdef XLAT_VAL_196
  | XLAT_VAL_196
#  endif
#  ifdef XLAT_VAL_197
  | XLAT_VAL_197
#  endif
#  ifdef XLAT_VAL_198
  | XLAT_VAL_198
#  endif
#  ifdef XLAT_VAL_199
  | XLAT_VAL_199
#  endif
  ,
 .flags_strsz = 0
#  ifdef XLAT_STR_0
  + sizeof(XLAT_STR_0)
#  endif
#  ifdef XLAT_STR_1
  + sizeof(XLAT_STR_1)
#  endif
#  ifdef XLAT_STR_2
  + sizeof(XLAT_STR_2)
#  endif
#  ifdef XLAT_STR_3
  + sizeof(XLAT_STR_3)
#  endif
#  ifdef XLAT_STR_4
  + sizeof(XLAT_STR_4)
#  endif
#  ifdef XLAT_STR_5
  + sizeof(XLAT_STR_5)
#  endif
#  ifdef XLAT_STR_6
  + sizeof(XLAT_STR_6)
#  endif
#  ifdef XLAT_STR_7
  + sizeof(XLAT_STR_7)
#  endif
#  ifdef XLAT_STR_8
  + sizeof(XLAT_STR_8)
#  endif
#  ifdef XLAT_STR_9
  + sizeof(XLAT_STR_9)
#  endif
#  ifdef XLAT_STR_10
  + sizeof(XLAT_STR_10)
#  endif
#  ifdef XLAT_STR_11
  + sizeof(XLAT_STR_11)
#  endif
#  ifdef XLAT_STR_12
  + sizeof(XLAT_STR_12)
#  endif
#  ifdef XLAT_STR_13
  + sizeof(XLAT_STR_13)
#  endif
#  ifdef XLAT_STR_14
  + sizeof(XLAT_STR_14)
#  endif
#  ifdef XLAT_STR_15
  + sizeof(XLAT_STR_15)
#  endif
#  ifdef XLAT_STR_16
  + sizeof(XLAT_STR_16)
#  endif
#  ifdef XLAT_STR_17
  + sizeof(XLAT_STR_17)
#  endif
#  ifdef XLAT_STR_18
  + sizeof(XLAT_STR_18)
#  endif
#  ifdef XLAT_STR_19
  + sizeof(XLAT_STR_19)
#  endif
#  ifdef XLAT_STR_20
  + sizeof(XLAT_STR_20)
#  endif
#  ifdef XLAT_STR_21
  + sizeof(XLAT_STR_21)
#  endif
#  ifdef XLAT_STR_22
  + sizeof(XLAT_STR_22)
#  endif
#  ifdef XLAT_STR_23
  + sizeof(XLAT_STR_23)
#  endif
#  ifdef XLAT_STR_24
  + sizeof(XLAT_STR_24)
#  endif
#  ifdef XLAT_STR_25
  + sizeof(XLAT_STR_25)
#  endif
#  ifdef XLAT_STR_26
  + sizeof(XLAT_STR_26)
#  endif
#  ifdef XLAT_STR_27
  + sizeof(XLAT_STR_27)
#  endif
#  ifdef XLAT_STR_28
  + sizeof(XLAT_STR_28)
#  endif
#  ifdef XLAT_STR_29
  + sizeof(XLAT_STR_29)
#  endif
#  ifdef XLAT_STR_30
  + sizeof(XLAT_STR_30)
#  endif
#  ifdef XLAT_STR_31
  + sizeof(XLAT_STR_31)
#  endif
#  ifdef XLAT_STR_32
  + sizeof(XLAT_STR_32)
#  endif
#  ifdef XLAT_STR_33
  + sizeof(XLAT_STR_33)
#  endif
#  ifdef XLAT_STR_34
  + sizeof(XLAT_STR_34)
#  endif
#  ifdef XLAT_STR_35
  + sizeof(XLAT_STR_35)
#  endif
#  ifdef XLAT_STR_36
  + sizeof(XLAT_STR_36)
#  endif
#  ifdef XLAT_STR_37
  + sizeof(XLAT_STR_37)
#  endif
#  ifdef XLAT_STR_38
  + sizeof(XLAT_STR_38)
#  endif
#  ifdef XLAT_STR_39
  + sizeof(XLAT_STR_39)
#  endif
#  ifdef XLAT_STR_40
  + sizeof(XLAT_STR_40)
#  endif
#  ifdef XLAT_STR_41
  + sizeof(XLAT_STR_41)
#  endif
#  ifdef XLAT_STR_42
  + sizeof(XLAT_STR_42)
#  endif
#  ifdef XLAT_STR_43
  + sizeof(XLAT_STR_43)
#  endif
#  ifdef XLAT_STR_44
  + sizeof(XLAT_STR_44)
#  endif
#  ifdef XLAT_STR_45
  + sizeof(XLAT_STR_45)
#  endif
#  ifdef XLAT_STR_46
  + sizeof(XLAT_STR_46)
#  endif
#  ifdef XLAT_STR_47
  + sizeof(XLAT_STR_47)
#  endif
#  ifdef XLAT_STR_48
  + sizeof(XLAT_STR_48)
#  endif
#  ifdef XLAT_STR_49
  + sizeof(XLAT_STR_49)
#  endif
#  ifdef XLAT_STR_50
  + sizeof(XLAT_STR_50)
#  endif
#  ifdef XLAT_STR_51
  + sizeof(XLAT_STR_51)
#  endif
#  ifdef XLAT_STR_52
  + sizeof(XLAT_STR_52)
#  endif
#  ifdef XLAT_STR_53
  + sizeof(XLAT_STR_53)
#  endif
#  ifdef XLAT_STR_54
  + sizeof(XLAT_STR_54)
#  endif
#  ifdef XLAT_STR_55
  + sizeof(XLAT_STR_55)
#  endif
#  ifdef XLAT_STR_56
  + sizeof(XLAT_STR_56)
#  endif
#  ifdef XLAT_STR_57
  + sizeof(XLAT_STR_57)
#  endif
#  ifdef XLAT_STR_58
  + sizeof(XLAT_STR_58)
#  endif
#  ifdef XLAT_STR_59
  + sizeof(XLAT_STR_59)
#  endif
#  ifdef XLAT_STR_60
  + sizeof(XLAT_STR_60)
#  endif
#  ifdef XLAT_STR_61
  + sizeof(XLAT_STR_61)
#  endif
#  ifdef XLAT_STR_62
  + sizeof(XLAT_STR_62)
#  endif
#  ifdef XLAT_STR_63
  + sizeof(XLAT_STR_63)
#  endif
#  ifdef XLAT_STR_64
  + sizeof(XLAT_STR_64)
#  endif
#  ifdef XLAT_STR_65
  + sizeof(XLAT_STR_65)
#  endif
#  ifdef XLAT_STR_66
  + sizeof(XLAT_STR_66)
#  endif
#  ifdef XLAT_STR_67
  + sizeof(XLAT_STR_67)
#  endif
#  ifdef XLAT_STR_68
  + sizeof(XLAT_STR_68)
#  endif
#  ifdef XLAT_STR_69
  + sizeof(XLAT_STR_69)
#  endif
#  ifdef XLAT_STR_70
  + sizeof(XLAT_STR_70)
#  endif
#  ifdef XLAT_STR_71
  + sizeof(XLAT_STR_71)
#  endif
#  ifdef XLAT_STR_72
  + sizeof(XLAT_STR_72)
#  endif
#  ifdef XLAT_STR_73
  + sizeof(XLAT_STR_73)
#  endif
#  ifdef XLAT_STR_74
  + sizeof(XLAT_STR_74)
#  endif
#  ifdef XLAT_STR_75
  + sizeof(XLAT_STR_75)
#  endif
#  ifdef XLAT_STR_76
  + sizeof(XLAT_STR_76)
#  endif
#  ifdef XLAT_STR_77
  + sizeof(XLAT_STR_77)
#  endif
#  ifdef XLAT_STR_78
  + sizeof(XLAT_STR_78)
#  endif
#  ifdef XLAT_STR_79
  + sizeof(XLAT_STR_79)
#  endif
#  ifdef XLAT_STR_80
  + sizeof(XLAT_STR_80)
#  endif
#  ifdef XLAT_STR_81
  + sizeof(XLAT_STR_81)
#  endif
#  ifdef XLAT_STR_82
  + sizeof(XLAT_STR_82)
#  endif
#  ifdef XLAT_STR_83
  + sizeof(XLAT_STR_83)
#  endif
#  ifdef XLAT_STR_84
  + sizeof(XLAT_STR_84)
#  endif
#  ifdef XLAT_STR_85
  + sizeof(XLAT_STR_85)
#  endif
#  ifdef XLAT_STR_86
  + sizeof(XLAT_STR_86)
#  endif
#  ifdef XLAT_STR_87
  + sizeof(XLAT_STR_87)
#  endif
#  ifdef XLAT_STR_88
  + sizeof(XLAT_STR_88)
#  endif
#  ifdef XLAT_STR_89
  + sizeof(XLAT_STR_89)
#  endif
#  ifdef XLAT_STR_90
  + sizeof(XLAT_STR_90)
#  endif
#  ifdef XLAT_STR_91
  + sizeof(XLAT_STR_91)
#  endif
#  ifdef XLAT_STR_92
  + sizeof(XLAT_STR_92)
#  endif
#  ifdef XLAT_STR_93
  + sizeof(XLAT_STR_93)
#  endif
#  ifdef XLAT_STR_94
  + sizeof(XLAT_STR_94)
#  endif
#  ifdef XLAT_STR_95
  + sizeof(XLAT_STR_95)
#  endif
#  ifdef XLAT_STR_96
  + sizeof(XLAT_STR_96)
#  endif
#  ifdef XLAT_STR_97
  + sizeof(XLAT_STR_97)
#  endif
#  ifdef XLAT_STR_98
  + sizeof(XLAT_STR_98)
#  endif
#  ifdef XLAT_STR_99
  + sizeof(XLAT_STR_99)
#  endif
#  ifdef XLAT_STR_100
  + sizeof(XLAT_STR_100)
#  endif
#  ifdef XLAT_STR_101
  + sizeof(XLAT_STR_101)
#  endif
#  ifdef XLAT_STR_102
  + sizeof(XLAT_STR_102)
#  endif
#  ifdef XLAT_STR_103
  + sizeof(XLAT_STR_103)
#  endif
#  ifdef XLAT_STR_104
  + sizeof(XLAT_STR_104)
#  endif
#  ifdef XLAT_STR_105
  + sizeof(XLAT_STR_105)
#  endif
#  ifdef XLAT_STR_106
  + sizeof(XLAT_STR_106)
#  endif
#  ifdef XLAT_STR_107
  + sizeof(XLAT_STR_107)
#  endif
#  ifdef XLAT_STR_108
  + sizeof(XLAT_STR_108)
#  endif
#  ifdef XLAT_STR_109
  + sizeof(XLAT_STR_109)
#  endif
#  ifdef XLAT_STR_110
  + sizeof(XLAT_STR_110)
#  endif
#  ifdef XLAT_STR_111
  + sizeof(XLAT_STR_111)
#  endif
#  ifdef XLAT_STR_112
  + sizeof(XLAT_STR_112)
#  endif
#  ifdef XLAT_STR_113
  + sizeof(XLAT_STR_113)
#  endif
#  ifdef XLAT_STR_114
  + sizeof(XLAT_STR_114)
#  endif
#  ifdef XLAT_STR_115
  + sizeof(XLAT_STR_115)
#  endif
#  ifdef XLAT_STR_116
  + sizeof(XLAT_STR_116)
#  endif
#  ifdef XLAT_STR_117
  + sizeof(XLAT_STR_117)
#  endif
#  ifdef XLAT_STR_118
  + sizeof(XLAT_STR_118)
#  endif
#  ifdef XLAT_STR_119
  + sizeof(XLAT_STR_119)
#  endif
#  ifdef XLAT_STR_120
  + sizeof(XLAT_STR_120)
#  endif
#  ifdef XLAT_STR_121
  + sizeof(XLAT_STR_121)
#  endif
#  ifdef XLAT_STR_122
  + sizeof(XLAT_STR_122)
#  endif
#  ifdef XLAT_STR_123
  + sizeof(XLAT_STR_123)
#  endif
#  ifdef XLAT_STR_124
  + sizeof(XLAT_STR_124)
#  endif
#  ifdef XLAT_STR_125
  + sizeof(XLAT_STR_125)
#  endif
#  ifdef XLAT_STR_126
  + sizeof(XLAT_STR_126)
#  endif
#  ifdef XLAT_STR_127
  + sizeof(XLAT_STR_127)
#  endif
#  ifdef XLAT_STR_128
  + sizeof(XLAT_STR_128)
#  endif
#  ifdef XLAT_STR_129
  + sizeof(XLAT_STR_129)
#  endif
#  ifdef XLAT_STR_130
  + sizeof(XLAT_STR_130)
#  endif
#  ifdef XLAT_STR_131
  + sizeof(XLAT_STR_131)
#  endif
#  ifdef XLAT_STR_132
  + sizeof(XLAT_STR_132)
#  endif
#  ifdef XLAT_STR_133
  + sizeof(XLAT_STR_133)
#  endif
#  ifdef XLAT_STR_134
  + sizeof(XLAT_STR_134)
#  endif
#  ifdef XLAT_STR_135
  + sizeof(XLAT_STR_135)
#  endif
#  ifdef XLAT_STR_136
  + sizeof(XLAT_STR_136)
#  endif
#  ifdef XLAT_STR_137
  + sizeof(XLAT_STR_137)
#  endif
#  ifdef XLAT_STR_138
  + sizeof(XLAT_STR_138)
#  endif
#  ifdef XLAT_STR_139
  + sizeof(XLAT_STR_139)
#  endif
#  ifdef XLAT_STR_140
  + sizeof(XLAT_STR_140)
#  endif
#  ifdef XLAT_STR_141
  + sizeof(XLAT_STR_141)
#  endif
#  ifdef XLAT_STR_142
  + sizeof(XLAT_STR_142)
#  endif
#  ifdef XLAT_STR_143
  + sizeof(XLAT_STR_143)
#  endif
#  ifdef XLAT_STR_144
  + sizeof(XLAT_STR_144)
#  endif
#  ifdef XLAT_STR_145
  + sizeof(XLAT_STR_145)
#  endif
#  ifdef XLAT_STR_146
  + sizeof(XLAT_STR_146)
#  endif
#  ifdef XLAT_STR_147
  + sizeof(XLAT_STR_147)
#  endif
#  ifdef XLAT_STR_148
  + sizeof(XLAT_STR_148)
#  endif
#  ifdef XLAT_STR_149
  + sizeof(XLAT_STR_149)
#  endif
#  ifdef XLAT_STR_150
  + sizeof(XLAT_STR_150)
#  endif
#  ifdef XLAT_STR_151
  + sizeof(XLAT_STR_151)
#  endif
#  ifdef XLAT_STR_152
  + sizeof(XLAT_STR_152)
#  endif
#  ifdef XLAT_STR_153
  + sizeof(XLAT_STR_153)
#  endif
#  ifdef XLAT_STR_154
  + sizeof(XLAT_STR_154)
#  endif
#  ifdef XLAT_STR_155
  + sizeof(XLAT_STR_155)
#  endif
#  ifdef XLAT_STR_156
  + sizeof(XLAT_STR_156)
#  endif
#  ifdef XLAT_STR_157
  + sizeof(XLAT_STR_157)
#  endif
#  ifdef XLAT_STR_158
  + sizeof(XLAT_STR_158)
#  endif
#  ifdef XLAT_STR_159
  + sizeof(XLAT_STR_159)
#  endif
#  ifdef XLAT_STR_160
  + sizeof(XLAT_STR_160)
#  endif
#  ifdef XLAT_STR_161
  + sizeof(XLAT_STR_161)
#  endif
#  ifdef XLAT_STR_162
  + sizeof(XLAT_STR_162)
#  endif
#  ifdef XLAT_STR_163
  + sizeof(XLAT_STR_163)
#  endif
#  ifdef XLAT_STR_164
  + sizeof(XLAT_STR_164)
#  endif
#  ifdef XLAT_STR_165
  + sizeof(XLAT_STR_165)
#  endif
#  ifdef XLAT_STR_166
  + sizeof(XLAT_STR_166)
#  endif
#  ifdef XLAT_STR_167
  + sizeof(XLAT_STR_167)
#  endif
#  ifdef XLAT_STR_168
  + sizeof(XLAT_STR_168)
#  endif
#  ifdef XLAT_STR_169
  + sizeof(XLAT_STR_169)
#  endif
#  ifdef XLAT_STR_170
  + sizeof(XLAT_STR_170)
#  endif
#  ifdef XLAT_STR_171
  + sizeof(XLAT_STR_171)
#  endif
#  ifdef XLAT_STR_172
  + sizeof(XLAT_STR_172)
#  endif
#  ifdef XLAT_STR_173
  + sizeof(XLAT_STR_173)
#  endif
#  ifdef XLAT_STR_174
  + sizeof(XLAT_STR_174)
#  endif
#  ifdef XLAT_STR_175
  + sizeof(XLAT_STR_175)
#  endif
#  ifdef XLAT_STR_176
  + sizeof(XLAT_STR_176)
#  endif
#  ifdef XLAT_STR_177
  + sizeof(XLAT_STR_177)
#  endif
#  ifdef XLAT_STR_178
  + sizeof(XLAT_STR_178)
#  endif
#  ifdef XLAT_STR_179
  + sizeof(XLAT_STR_179)
#  endif
#  ifdef XLAT_STR_180
  + sizeof(XLAT_STR_180)
#  endif
#  ifdef XLAT_STR_181
  + sizeof(XLAT_STR_181)
#  endif
#  ifdef XLAT_STR_182
  + sizeof(XLAT_STR_182)
#  endif
#  ifdef XLAT_STR_183
  + sizeof(XLAT_STR_183)
#  endif
#  ifdef XLAT_STR_184
  + sizeof(XLAT_STR_184)
#  endif
#  ifdef XLAT_STR_185
  + sizeof(XLAT_STR_185)
#  endif
#  ifdef XLAT_STR_186
  + sizeof(XLAT_STR_186)
#  endif
#  ifdef XLAT_STR_187
  + sizeof(XLAT_STR_187)
#  endif
#  ifdef XLAT_STR_188
  + sizeof(XLAT_STR_188)
#  endif
#  ifdef XLAT_STR_189
  + sizeof(XLAT_STR_189)
#  endif
#  ifdef XLAT_STR_190
  + sizeof(XLAT_STR_190)
#  endif
#  ifdef XLAT_STR_191
  + sizeof(XLAT_STR_191)
#  endif
#  ifdef XLAT_STR_192
  + sizeof(XLAT_STR_192)
#  endif
#  ifdef XLAT_STR_193
  + sizeof(XLAT_STR_193)
#  endif
#  ifdef XLAT_STR_194
  + sizeof(XLAT_STR_194)
#  endif
#  ifdef XLAT_STR_195
  + sizeof(XLAT_STR_195)
#  endif
#  ifdef XLAT_STR_196
  + sizeof(XLAT_STR_196)
#  endif
#  ifdef XLAT_STR_197
  + sizeof(XLAT_STR_197)
#  endif
#  ifdef XLAT_STR_198
  + sizeof(XLAT_STR_198)
#  endif
#  ifdef XLAT_STR_199
  + sizeof(XLAT_STR_199)
#  endif
  ,
} };
DIAG_POP_IGNORE_TAUTOLOGICAL_CONSTANT_COMPARE

#  undef XLAT_STR_0
#  undef XLAT_VAL_0
#  undef XLAT_STR_1
#  undef XLAT_VAL_1
#  undef XLAT_STR_2
#  undef XLAT_VAL_2
#  undef XLAT_STR_3
#  undef XLAT_VAL_3
#  undef XLAT_STR_4
#  undef XLAT_VAL_4
#  undef XLAT_STR_5
#  undef XLAT_VAL_5
#  undef XLAT_STR_6
#  undef XLAT_VAL_6
#  undef XLAT_STR_7
#  undef XLAT_VAL_7
#  undef XLAT_STR_8
#  undef XLAT_VAL_8
#  undef XLAT_STR_9
#  undef XLAT_VAL_9
#  undef XLAT_STR_10
#  undef XLAT_VAL_10
#  undef XLAT_STR_11
#  undef XLAT_VAL_11
#  undef XLAT_STR_12
#  undef XLAT_VAL_12
#  undef XLAT_STR_13
#  undef XLAT_VAL_13
#  undef XLAT_STR_14
#  undef XLAT_VAL_14
#  undef XLAT_STR_15
#  undef XLAT_VAL_15
#  undef XLAT_STR_16
#  undef XLAT_VAL_16
#  undef XLAT_STR_17
#  undef XLAT_VAL_17
#  undef XLAT_STR_18
#  undef XLAT_VAL_18
#  undef XLAT_STR_19
#  undef XLAT_VAL_19
#  undef XLAT_STR_20
#  undef XLAT_VAL_20
#  undef XLAT_STR_21
#  undef XLAT_VAL_21
#  undef XLAT_STR_22
#  undef XLAT_VAL_22
#  undef XLAT_STR_23
#  undef XLAT_VAL_23
#  undef XLAT_STR_24
#  undef XLAT_VAL_24
#  undef XLAT_STR_25
#  undef XLAT_VAL_25
#  undef XLAT_STR_26
#  undef XLAT_VAL_26
#  undef XLAT_STR_27
#  undef XLAT_VAL_27
#  undef XLAT_STR_28
#  undef XLAT_VAL_28
#  undef XLAT_STR_29
#  undef XLAT_VAL_29
#  undef XLAT_STR_30
#  undef XLAT_VAL_30
#  undef XLAT_STR_31
#  undef XLAT_VAL_31
#  undef XLAT_STR_32
#  undef XLAT_VAL_32
#  undef XLAT_STR_33
#  undef XLAT_VAL_33
#  undef XLAT_STR_34
#  undef XLAT_VAL_34
#  undef XLAT_STR_35
#  undef XLAT_VAL_35
#  undef XLAT_STR_36
#  undef XLAT_VAL_36
#  undef XLAT_STR_37
#  undef XLAT_VAL_37
#  undef XLAT_STR_38
#  undef XLAT_VAL_38
#  undef XLAT_STR_39
#  undef XLAT_VAL_39
#  undef XLAT_STR_40
#  undef XLAT_VAL_40
#  undef XLAT_STR_41
#  undef XLAT_VAL_41
#  undef XLAT_STR_42
#  undef XLAT_VAL_42
#  undef XLAT_STR_43
#  undef XLAT_VAL_43
#  undef XLAT_STR_44
#  undef XLAT_VAL_44
#  undef XLAT_STR_45
#  undef XLAT_VAL_45
#  undef XLAT_STR_46
#  undef XLAT_VAL_46
#  undef XLAT_STR_47
#  undef XLAT_VAL_47
#  undef XLAT_STR_48
#  undef XLAT_VAL_48
#  undef XLAT_STR_49
#  undef XLAT_VAL_49
#  undef XLAT_STR_50
#  undef XLAT_VAL_50
#  undef XLAT_STR_51
#  undef XLAT_VAL_51
#  undef XLAT_STR_52
#  undef XLAT_VAL_52
#  undef XLAT_STR_53
#  undef XLAT_VAL_53
#  undef XLAT_STR_54
#  undef XLAT_VAL_54
#  undef XLAT_STR_55
#  undef XLAT_VAL_55
#  undef XLAT_STR_56
#  undef XLAT_VAL_56
#  undef XLAT_STR_57
#  undef XLAT_VAL_57
#  undef XLAT_STR_58
#  undef XLAT_VAL_58
#  undef XLAT_STR_59
#  undef XLAT_VAL_59
#  undef XLAT_STR_60
#  undef XLAT_VAL_60
#  undef XLAT_STR_61
#  undef XLAT_VAL_61
#  undef XLAT_STR_62
#  undef XLAT_VAL_62
#  undef XLAT_STR_63
#  undef XLAT_VAL_63
#  undef XLAT_STR_64
#  undef XLAT_VAL_64
#  undef XLAT_STR_65
#  undef XLAT_VAL_65
#  undef XLAT_STR_66
#  undef XLAT_VAL_66
#  undef XLAT_STR_67
#  undef XLAT_VAL_67
#  undef XLAT_STR_68
#  undef XLAT_VAL_68
#  undef XLAT_STR_69
#  undef XLAT_VAL_69
#  undef XLAT_STR_70
#  undef XLAT_VAL_70
#  undef XLAT_STR_71
#  undef XLAT_VAL_71
#  undef XLAT_STR_72
#  undef XLAT_VAL_72
#  undef XLAT_STR_73
#  undef XLAT_VAL_73
#  undef XLAT_STR_74
#  undef XLAT_VAL_74
#  undef XLAT_STR_75
#  undef XLAT_VAL_75
#  undef XLAT_STR_76
#  undef XLAT_VAL_76
#  undef XLAT_STR_77
#  undef XLAT_VAL_77
#  undef XLAT_STR_78
#  undef XLAT_VAL_78
#  undef XLAT_STR_79
#  undef XLAT_VAL_79
#  undef XLAT_STR_80
#  undef XLAT_VAL_80
#  undef XLAT_STR_81
#  undef XLAT_VAL_81
#  undef XLAT_STR_82
#  undef XLAT_VAL_82
#  undef XLAT_STR_83
#  undef XLAT_VAL_83
#  undef XLAT_STR_84
#  undef XLAT_VAL_84
#  undef XLAT_STR_85
#  undef XLAT_VAL_85
#  undef XLAT_STR_86
#  undef XLAT_VAL_86
#  undef XLAT_STR_87
#  undef XLAT_VAL_87
#  undef XLAT_STR_88
#  undef XLAT_VAL_88
#  undef XLAT_STR_89
#  undef XLAT_VAL_89
#  undef XLAT_STR_90
#  undef XLAT_VAL_90
#  undef XLAT_STR_91
#  undef XLAT_VAL_91
#  undef XLAT_STR_92
#  undef XLAT_VAL_92
#  undef XLAT_STR_93
#  undef XLAT_VAL_93
#  undef XLAT_STR_94
#  undef XLAT_VAL_94
#  undef XLAT_STR_95
#  undef XLAT_VAL_95
#  undef XLAT_STR_96
#  undef XLAT_VAL_96
#  undef XLAT_STR_97
#  undef XLAT_VAL_97
#  undef XLAT_STR_98
#  undef XLAT_VAL_98
#  undef XLAT_STR_99
#  undef XLAT_VAL_99
#  undef XLAT_STR_100
#  undef XLAT_VAL_100
#  undef XLAT_STR_101
#  undef XLAT_VAL_101
#  undef XLAT_STR_102
#  undef XLAT_VAL_102
#  undef XLAT_STR_103
#  undef XLAT_VAL_103
#  undef XLAT_STR_104
#  undef XLAT_VAL_104
#  undef XLAT_STR_105
#  undef XLAT_VAL_105
#  undef XLAT_STR_106
#  undef XLAT_VAL_106
#  undef XLAT_STR_107
#  undef XLAT_VAL_107
#  undef XLAT_STR_108
#  undef XLAT_VAL_108
#  undef XLAT_STR_109
#  undef XLAT_VAL_109
#  undef XLAT_STR_110
#  undef XLAT_VAL_110
#  undef XLAT_STR_111
#  undef XLAT_VAL_111
#  undef XLAT_STR_112
#  undef XLAT_VAL_112
#  undef XLAT_STR_113
#  undef XLAT_VAL_113
#  undef XLAT_STR_114
#  undef XLAT_VAL_114
#  undef XLAT_STR_115
#  undef XLAT_VAL_115
#  undef XLAT_STR_116
#  undef XLAT_VAL_116
#  undef XLAT_STR_117
#  undef XLAT_VAL_117
#  undef XLAT_STR_118
#  undef XLAT_VAL_118
#  undef XLAT_STR_119
#  undef XLAT_VAL_119
#  undef XLAT_STR_120
#  undef XLAT_VAL_120
#  undef XLAT_STR_121
#  undef XLAT_VAL_121
#  undef XLAT_STR_122
#  undef XLAT_VAL_122
#  undef XLAT_STR_123
#  undef XLAT_VAL_123
#  undef XLAT_STR_124
#  undef XLAT_VAL_124
#  undef XLAT_STR_125
#  undef XLAT_VAL_125
#  undef XLAT_STR_126
#  undef XLAT_VAL_126
#  undef XLAT_STR_127
#  undef XLAT_VAL_127
#  undef XLAT_STR_128
#  undef XLAT_VAL_128
#  undef XLAT_STR_129
#  undef XLAT_VAL_129
#  undef XLAT_STR_130
#  undef XLAT_VAL_130
#  undef XLAT_STR_131
#  undef XLAT_VAL_131
#  undef XLAT_STR_132
#  undef XLAT_VAL_132
#  undef XLAT_STR_133
#  undef XLAT_VAL_133
#  undef XLAT_STR_134
#  undef XLAT_VAL_134
#  undef XLAT_STR_135
#  undef XLAT_VAL_135
#  undef XLAT_STR_136
#  undef XLAT_VAL_136
#  undef XLAT_STR_137
#  undef XLAT_VAL_137
#  undef XLAT_STR_138
#  undef XLAT_VAL_138
#  undef XLAT_STR_139
#  undef XLAT_VAL_139
#  undef XLAT_STR_140
#  undef XLAT_VAL_140
#  undef XLAT_STR_141
#  undef XLAT_VAL_141
#  undef XLAT_STR_142
#  undef XLAT_VAL_142
#  undef XLAT_STR_143
#  undef XLAT_VAL_143
#  undef XLAT_STR_144
#  undef XLAT_VAL_144
#  undef XLAT_STR_145
#  undef XLAT_VAL_145
#  undef XLAT_STR_146
#  undef XLAT_VAL_146
#  undef XLAT_STR_147
#  undef XLAT_VAL_147
#  undef XLAT_STR_148
#  undef XLAT_VAL_148
#  undef XLAT_STR_149
#  undef XLAT_VAL_149
#  undef XLAT_STR_150
#  undef XLAT_VAL_150
#  undef XLAT_STR_151
#  undef XLAT_VAL_151
#  undef XLAT_STR_152
#  undef XLAT_VAL_152
#  undef XLAT_STR_153
#  undef XLAT_VAL_153
#  undef XLAT_STR_154
#  undef XLAT_VAL_154
#  undef XLAT_STR_155
#  undef XLAT_VAL_155
#  undef XLAT_STR_156
#  undef XLAT_VAL_156
#  undef XLAT_STR_157
#  undef XLAT_VAL_157
#  undef XLAT_STR_158
#  undef XLAT_VAL_158
#  undef XLAT_STR_159
#  undef XLAT_VAL_159
#  undef XLAT_STR_160
#  undef XLAT_VAL_160
#  undef XLAT_STR_161
#  undef XLAT_VAL_161
#  undef XLAT_STR_162
#  undef XLAT_VAL_162
#  undef XLAT_STR_163
#  undef XLAT_VAL_163
#  undef XLAT_STR_164
#  undef XLAT_VAL_164
#  undef XLAT_STR_165
#  undef XLAT_VAL_165
#  undef XLAT_STR_166
#  undef XLAT_VAL_166
#  undef XLAT_STR_167
#  undef XLAT_VAL_167
#  undef XLAT_STR_168
#  undef XLAT_VAL_168
#  undef XLAT_STR_169
#  undef XLAT_VAL_169
#  undef XLAT_STR_170
#  undef XLAT_VAL_170
#  undef XLAT_STR_171
#  undef XLAT_VAL_171
#  undef XLAT_STR_172
#  undef XLAT_VAL_172
#  undef XLAT_STR_173
#  undef XLAT_VAL_173
#  undef XLAT_STR_174
#  undef XLAT_VAL_174
#  undef XLAT_STR_175
#  undef XLAT_VAL_175
#  undef XLAT_STR_176
#  undef XLAT_VAL_176
#  undef XLAT_STR_177
#  undef XLAT_VAL_177
#  undef XLAT_STR_178
#  undef XLAT_VAL_178
#  undef XLAT_STR_179
#  undef XLAT_VAL_179
#  undef XLAT_STR_180
#  undef XLAT_VAL_180
#  undef XLAT_STR_181
#  undef XLAT_VAL_181
#  undef XLAT_STR_182
#  undef XLAT_VAL_182
#  undef XLAT_STR_183
#  undef XLAT_VAL_183
#  undef XLAT_STR_184
#  undef XLAT_VAL_184
#  undef XLAT_STR_185
#  undef XLAT_VAL_185
#  undef XLAT_STR_186
#  undef XLAT_VAL_186
#  undef XLAT_STR_187
#  undef XLAT_VAL_187
#  undef XLAT_STR_188
#  undef XLAT_VAL_188
#  undef XLAT_STR_189
#  undef XLAT_VAL_189
#  undef XLAT_STR_190
#  undef XLAT_VAL_190
#  undef XLAT_STR_191
#  undef XLAT_VAL_191
#  undef XLAT_STR_192
#  undef XLAT_VAL_192
#  undef XLAT_STR_193
#  undef XLAT_VAL_193
#  undef XLAT_STR_194
#  undef XLAT_VAL_194
#  undef XLAT_STR_195
#  undef XLAT_VAL_195
#  undef XLAT_STR_196
#  undef XLAT_VAL_196
#  undef XLAT_STR_197
#  undef XLAT_VAL_197
#  undef XLAT_STR_198
#  undef XLAT_VAL_198
#  undef XLAT_STR_199
#  undef XLAT_VAL_199
# endif /* !IN_MPERS */

#endif /* !XLAT_MACROS_ONLY */
